#!/usr/bin/env python3
"""
Optimized Raw Data Processor (é«˜æ€§èƒ½ ETL å¤„ç†è„šæœ¬ - ç»„åˆä¼˜åŒ–ç‰ˆ)
==============================================================================

åŠŸèƒ½è¯´æ˜:
1. **é«˜æ€§èƒ½ ETL**: ä¸“ä¸ºå…¨é‡é‡è½½å’Œåƒä¸‡çº§ Backfill åœºæ™¯è®¾è®¡ï¼Œååé‡è¾ƒæ ‡å‡†ç‰ˆæœ¬æå‡ 10 å€ä»¥ä¸Šã€‚
2. **æ•°æ®æ ‡å‡†åŒ–**: å°† `RawMarketData` (JSON) è½¬æ¢ä¸ºç»“æ„åŒ–çš„ `MarketDataDaily` (æ—¥çº¿) å’Œ `MarketSnapshot` (å®æ—¶å¿«ç…§)ã€‚

æ ¸å¿ƒæŠ€æœ¯æ¶æ„:
========================================

I. Performance Optimizations (æ€§èƒ½ä¼˜åŒ–)
----------------------------------------
- **é¢„åŠ è½½ç¼“å­˜ (Pre-fetch)**: è„šæœ¬åœ¨å¤„ç†èµ„äº§å‰ï¼Œä¼šä¸€æ¬¡æ€§ä»æ•°æ®åº“æ‹‰å–è¯¥ Symbol çš„æ‰€æœ‰å·²çŸ¥å†å²è®°å½•å¹¶å­˜å‚¨åœ¨å†…å­˜ Map ä¸­ï¼Œæ¶ˆé™¤å¾ªç¯å†…çš„ N æ¬¡ SQL æŸ¥è¯¢ï¼Œè§£å†³ "N+1" æŸ¥è¯¢ç“¶é¢ˆã€‚
- **æ‰¹é‡ UPSERT**: ä½¿ç”¨ SQLite çš„ `INSERT OR REPLACE` åŸç”Ÿ SQLï¼Œé…åˆ batch æäº¤ï¼Œç¡®ä¿å¤§è§„æ¨¡æ•°æ®å†™å…¥æ—¶çš„åŸå­æ€§ä¸é€Ÿåº¦ã€‚

II. Market Close Guard (æ”¶ç›˜å‡†å…¥ä¿æŠ¤)
----------------------------------------
è¿™æ˜¯æœ¬ç³»ç»Ÿæœ€å…³é”®çš„æ•°æ®å®Œæ•´æ€§ä¿æŠ¤é€»è¾‘ï¼Œé˜²æ­¢äº¤æ˜“è¿‡ç¨‹ä¸­çš„ä¸å®Œæ•´ä»·æ ¼æ±¡æŸ“å†å²æ—¥çº¿ã€‚

- **é€»è¾‘**: 
  - åªæœ‰ **å†å²æ•°æ® (Timestamp < Today)** æˆ– **å·²ç¡®è®¤æ”¶ç›˜æ•°æ®** å…è®¸è¿›å…¥ `MarketDataDaily`ã€‚
  - **æ”¶ç›˜ç¡®è®¤é˜ˆå€¼** (åŸºäº `fetch_time`):
    - **CN (Aè‚¡)**: æ”¶ç›˜æ—¶é—´ 15:00ï¼Œå‡†å…¥æ—¶é—´ >= 16:00 (1å°æ—¶ç¼“å†²)ã€‚
    - **HK (æ¸¯è‚¡)**: æ”¶ç›˜æ—¶é—´ 16:00ï¼Œå‡†å…¥æ—¶é—´ >= 17:00ã€‚
    - **US (ç¾è‚¡)**: é€»è¾‘ä¿ç•™åœ¨ä»£ç ä¸­ï¼Œé’ˆå¯¹å¤æ‚çš„å†¬/å¤ä»¤æ—¶åšçµæ´»åˆ¤æ–­ã€‚
- **ç»“æœ**: è‹¥å¸‚åœºæœªå®Œå…¨æ”¶ç›˜ï¼Œæ•°æ®ä»…å†™å…¥ `MarketSnapshot` (å¿«ç…§)ï¼Œä¸è¿›å…¥æ—¥çº¿å†å²ã€‚

III. Dual-Path Storage (åŒè·¯å­˜å‚¨æµ)
----------------------------------------
1. **Path A -> MarketDataDaily**: é•¿æœŸå†å²è¡¨ï¼Œå­˜å‚¨å½’ä¸€åŒ–åçš„æ­£å¼æ—¥çº¿è¡Œæƒ…ã€‚
2. **Path B -> MarketSnapshot**: ç¬æ—¶çŠ¶æ€è¡¨ï¼Œå§‹ç»ˆå­˜å‚¨è§£æå¾—åˆ°çš„æœ€æ–°ä¸€æ¡è®°å½•ï¼Œç”¨äºå‰ç«¯å®æ—¶çœ‹æ¿ã€‚

IV. Timestamp Normalization (æ—¶é—´æˆ³å½’ä¸€åŒ–)
----------------------------------------
ç”±äº Yahoo å†å²æ•°æ®é€šå¸¸å°†æ—¶é—´è®¾ä¸º `00:00:00`ï¼Œæœ¬è„šæœ¬ä¼šè‡ªåŠ¨è¿›è¡Œä¿®æ­£ï¼š
- **US/HK**: -> `16:00:00`
- **CN**: -> `15:00:00`
- è¿™ç§ä¸€è‡´æ€§å½’ä¸€åŒ–æ˜¯è®¡ç®— PE/PB ä¼°å€¼æŒ‚è½½æ—¥çº¿æ•°æ®çš„å‰æã€‚

V. Sequence Analysis (æ—¶åºåˆ†æ)
----------------------------------------
- **æ¶¨è·Œé€»è¾‘**: è„šæœ¬ä¼šå›æº¯å†…å­˜ä¸­çš„ Prev Record è®¡ç®— `change` (æ¶¨è·Œé¢) å’Œ `pct_change` (æ¶¨è·Œå¹…)ã€‚
- **ç¼ºå¤±è¡¥å¿**: è‹¥æ•°æ®æºç¼ºå¤±å¼€ç›˜/æœ€é«˜/æœ€ä½ä»·ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨ä»¥æ”¶ç›˜ä»·å¡«å……ï¼Œç¡®ä¿è®°å½•å®Œæ•´æ€§ã€‚

ä½œè€…: Antigravity
æ—¥æœŸ: 2026-01-23
"""

import sys
sys.path.append('backend')

from sqlmodel import Session, create_engine, select, text
from models import RawMarketData, MarketDataDaily, MarketSnapshot
from etl_service import ETLService
from datetime import datetime
import json
import pandas as pd
import time

engine = create_engine('sqlite:///backend/database.db')

def process_raw_optimized(raw_id: int, session: Session):
    """ä¼˜åŒ–ç‰ˆETLå¤„ç† - å•ä¸ªèµ„äº§"""
    
    # 1. è·å–RAWè®°å½•
    raw_record = session.get(RawMarketData, raw_id)
    if not raw_record or raw_record.processed:
        return 0
    
    # 2. è§£æpayload
    try:
        payload_data = json.loads(raw_record.payload)
        if isinstance(payload_data, dict) and 'data' in payload_data:
            data_list = payload_data['data']
        elif isinstance(payload_data, list):
            data_list = payload_data
        else:
            return 0
        
        if not data_list:
            raw_record.processed = True
            return 0
        
        df = pd.DataFrame(data_list)
        
        # 3. âœ… é¢„åŠ è½½å·²æœ‰æ•°æ® (ä¸€æ¬¡æŸ¥è¯¢)
        existing_data = {}
        result = session.exec(
            select(MarketDataDaily)
            .where(MarketDataDaily.symbol == raw_record.symbol)
            .where(MarketDataDaily.market == raw_record.market)
            .order_by(MarketDataDaily.timestamp)
        ).all()
        
        for record in result:
            existing_data[record.timestamp] = record.close
        
        # 4. æ‰¹é‡å‡†å¤‡æ•°æ®
        records_to_insert = []
        last_close = None
        
        for _, row in df.iterrows():
            # æ—¶é—´æˆ³å¤„ç†
            timestamp = pd.to_datetime(row.get('timestamp'))
            if pd.isna(timestamp):
                continue
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºå†å²æ•°æ®ï¼ˆéä»Šæ—¥ï¼‰
            current_date = datetime.now().date()
            row_date = timestamp.date()
            is_history = row_date < current_date
            
            # å¸‚åœºæ”¶ç›˜æ—¶é—´åˆ¤æ–­
            market_closed = False
            
            if is_history:
                market_closed = True
            else:
                # å¦‚æœæ˜¯å½“å¤©æ•°æ®ï¼Œå¿…é¡»æ£€æŸ¥ fetch_time æ˜¯å¦å·²è¿‡æ”¶ç›˜æ—¶é—´ + 1å°æ—¶ç¼“å†²
                # åªæœ‰ "å®Œå…¨æ”¶ç›˜å1å°æ—¶" çš„æ•°æ®æ‰å…è®¸å†™å…¥ Daily è¡¨
                # å¦‚æœæ˜¯å½“å¤©æ•°æ®ï¼Œå¿…é¡»æ£€æŸ¥ fetch_time æ˜¯å¦å·²è¿‡æ”¶ç›˜æ—¶é—´ + 1å°æ—¶ç¼“å†²
                # åªæœ‰ "å®Œå…¨æ”¶ç›˜å1å°æ—¶" çš„æ•°æ®æ‰å…è®¸å†™å…¥ Daily è¡¨
                try:
                     ft = raw_record.fetch_time
                     if isinstance(ft, str):
                         # Try parsing with and without microseconds
                         try:
                             ft_dt = datetime.strptime(ft, '%Y-%m-%d %H:%M:%S.%f')
                         except ValueError:
                             try:
                                 ft_dt = datetime.strptime(ft, '%Y-%m-%d %H:%M:%S')
                             except ValueError:
                                  # Fallback for ISO format 'T'
                                  ft_dt = datetime.fromisoformat(ft)
                     elif isinstance(ft, datetime):
                         ft_dt = ft
                     else:
                         # Unexpected type, maybe skip safety check or default closed?
                         # Default to now() if missing? No, safer to assume open/false.
                         raise ValueError(f"Unknown fetch_time type: {type(ft)}")

                     ft_hour = ft_dt.hour
                     
                     if raw_record.market == 'CN':
                         # CN Close 15:00. Safe > 16:00
                         if ft_hour >= 16: market_closed = True
                     
                     elif raw_record.market == 'HK':
                         # HK Close 16:00 (Auction ~16:10). Safe > 17:00
                         if ft_hour >= 17: market_closed = True
                     
                     elif raw_record.market == 'US':
                         # US Close varies. Default False.
                         pass
                         
                except Exception as e:
                     # Fallback if fetch_time parse fail -> Safe side: False
                     # print(f"DEBUG: Time parse error: {e}")
                     market_closed = False
            
            # åªæœ‰å†å²æ•°æ® æˆ– ä»Šæ—¥å·²æ”¶ç›˜ æ‰æ ‡å‡†åŒ–æ”¶ç›˜æ—¶é—´
            if is_history or market_closed:
                if timestamp.hour == 0 and timestamp.minute == 0:
                    if raw_record.market == 'US':
                        timestamp = timestamp.replace(hour=16)
                    elif raw_record.market == 'HK':
                        timestamp = timestamp.replace(hour=16)
                    elif raw_record.market == 'CN':
                        timestamp = timestamp.replace(hour=15)
            
            timestamp_str = timestamp.strftime('%Y-%m-%d %H:%M:%S')
            
            # è·å–å‰æ”¶ç›˜ä»·
            prev_close = row.get('prev_close')
            if prev_close is None:
                # ä»é¢„åŠ è½½æ•°æ®ä¸­æŸ¥æ‰¾
                prev_timestamps = [ts for ts in existing_data.keys() if ts < timestamp_str]
                if prev_timestamps:
                    prev_timestamp = max(prev_timestamps)
                    prev_close = existing_data[prev_timestamp]
                elif last_close is not None:
                    prev_close = last_close
            
            # è®¡ç®—æ¶¨è·Œå¹…
            close_price = float(row['close'])
            change = None
            pct_change = None
            
            if prev_close:
                change = close_price - prev_close
                pct_change = (change / prev_close) * 100
            
            # å‡†å¤‡è®°å½•
            raw_close = row.get('close')
            if pd.isna(raw_close) or raw_close is None:
                continue
            
            close_price = float(raw_close)
            
            def clean_val(val, fallback):
                if pd.isna(val) or val is None: return fallback
                return float(val)

            record_dict = {
                'symbol': raw_record.symbol,
                'market': raw_record.market,
                'timestamp': timestamp_str,
                'open': clean_val(row.get('open'), close_price),
                'high': clean_val(row.get('high'), close_price),
                'low': clean_val(row.get('low'), close_price),
                'close': close_price,
                'volume': int(row.get('volume', 0)),
                'change': change,
                'pct_change': pct_change,
                'prev_close': prev_close,
                'updated_at': datetime.now()
            }
            
            # é€»è¾‘åˆ†æµ:
            # 1. Dailyè¡¨: ä»…å†™å…¥å†å²æ•°æ® æˆ– ä»Šæ—¥å·²æ”¶ç›˜æ•°æ®
            # 2. Snapshotè¡¨: å§‹ç»ˆå†™å…¥æœ€æ–°ä¸€æ¡
            
            # å…è®¸å†™å…¥æ—¥çº¿è¡¨çš„æ¡ä»¶: æ˜¯å†å²æ•°æ®ï¼Œæˆ–è€… (æ˜¯ä»Šæ—¥æ•°æ® ä¸” å¸‚åœºå·²æ”¶ç›˜)
            if is_history or market_closed:
                records_to_insert.append(record_dict)
                last_close = close_price
                existing_data[timestamp_str] = close_price
            else:
                # å³ä½¿ä¸å†™å…¥æ—¥çº¿è¡¨ï¼Œä¹Ÿè¦æ›´æ–°last_closeç”¨äºåç»­è®¡ç®—? 
                # ä¸ï¼Œæ—¥çº¿è¿ç»­æ€§åº”åŸºäºå·²ç¡®è®¤çš„æ”¶ç›˜ä»·
                pass
                
            # ç”¨äºæ›´æ–°å¿«ç…§çš„å§‹ç»ˆæ˜¯æœ€æ–°ä¸€æ¡ (æ— è®ºæ˜¯å¦æ”¶ç›˜)
            last_record_for_snapshot = record_dict
        
        # 5. âœ… æ‰¹é‡æ’å…¥ Daily (ä»…åˆè§„æ•°æ®)
        if records_to_insert:
            # ä½¿ç”¨åŸç”ŸSQLæ‰¹é‡UPSERT
            for record in records_to_insert:
                session.exec(text("""
                    INSERT OR REPLACE INTO marketdatadaily 
                    (symbol, market, timestamp, open, high, low, close, volume, 
                     change, pct_change, prev_close, updated_at)
                    VALUES 
                    (:symbol, :market, :timestamp, :open, :high, :low, :close, :volume,
                     :change, :pct_change, :prev_close, :updated_at)
                """).bindparams(**record))
        
        # 6. æ›´æ–°Snapshot (å§‹ç»ˆä½¿ç”¨æœ€æ–°ä¸€æ¡è§£æåˆ°çš„æ•°æ®)
        if 'last_record_for_snapshot' in locals() and last_record_for_snapshot:
            # å¦‚æœæ²¡æœ‰è¿›å…¥Daily (ä¾‹å¦‚ç›˜ä¸­)ï¼Œéœ€è¦ç¡®ä¿Change/PctChangeè®¡ç®—æ­£ç¡®
            # ç›˜ä¸­æ•°æ®çš„prev_closeåº”è¯¥å–è‡ªæ˜¨æ—¥æ”¶ç›˜ (Dailyè¡¨ä¸­æœ€è¿‘çš„ä¸€æ¡)
            # ä¸Šé¢çš„é€»è¾‘ä¸­ï¼Œprev_close å·²ç»å°è¯•è·å–äº†ã€‚
            
            last_record = last_record_for_snapshot
            session.exec(text("""
                INSERT OR REPLACE INTO marketsnapshot
                (symbol, market, price, open, high, low, prev_close, change, pct_change,
                 volume, timestamp, data_source, fetch_time, updated_at)
                VALUES
                (:symbol, :market, :close, :open, :high, :low, :prev_close, :change, :pct_change,
                 :volume, :timestamp, 'daily_close', :fetch_time, :updated_at)
            """).bindparams(
                symbol=last_record['symbol'],
                market=last_record['market'],
                close=last_record['close'],
                open=last_record['open'],
                high=last_record['high'],
                low=last_record['low'],
                prev_close=last_record['prev_close'],
                change=last_record['change'],
                pct_change=last_record['pct_change'],
                volume=last_record['volume'],
                timestamp=last_record['timestamp'],
                fetch_time=datetime.now(),
                updated_at=datetime.now()
            ))
        
        # 7. æ ‡è®°å®Œæˆ
        raw_record.processed = True
        session.add(raw_record)
        
        return len(records_to_insert)
        
    except Exception as e:
        print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
        raw_record.error_log = str(e)
        session.add(raw_record)
        return 0

def main():
    print("=" * 80)
    print("é«˜æ€§èƒ½ ETL å¤„ç† (ç»„åˆä¼˜åŒ–ç‰ˆ)")
    print("=" * 80)
    print(f"æ‰§è¡Œæ—¶é—´: {datetime.now()}")
    print()
    
    with Session(engine) as session:
        # æŸ¥è¯¢æ‰€æœ‰æœªå¤„ç†è®°å½•
        unprocessed = session.exec(
            select(RawMarketData).where(RawMarketData.processed == False)
        ).all()
        
        total = len(unprocessed)
        
        if total == 0:
            print("âœ… æ²¡æœ‰å¾…å¤„ç†çš„è®°å½•")
            return
        
        print(f"ğŸ“‹ å¾…å¤„ç†è®°å½•: {total} æ¡")
        print()
        
        success = 0
        failed = 0
        total_records = 0
        start_time = time.time()
        
        for idx, record in enumerate(unprocessed, 1):
            asset_start = time.time()
            
            print(f"[{idx}/{total}] å¤„ç† {record.symbol}...", end=" ", flush=True)
            
            try:
                count = process_raw_optimized(record.id, session)
                session.commit()  # æ¯ä¸ªèµ„äº§æäº¤ä¸€æ¬¡
                
                asset_time = time.time() - asset_start
                success += 1
                total_records += count
                
                print(f"âœ… {count:,}æ¡ ({asset_time:.1f}ç§’)")
                
            except Exception as e:
                failed += 1
                print(f"âŒ {e}")
                session.rollback()
        
        elapsed = time.time() - start_time
        
        print()
        print("=" * 80)
        print("å¤„ç†å®Œæˆ")
        print("=" * 80)
        print(f"âœ… æˆåŠŸ: {success}/{total}")
        print(f"âŒ å¤±è´¥: {failed}")
        print(f"ğŸ“Š æ€»è®°å½•: {total_records:,} æ¡")
        print(f"â±ï¸  æ€»æ—¶é—´: {elapsed/60:.1f} åˆ†é’Ÿ")
        print(f"âš¡ å¹³å‡é€Ÿåº¦: {elapsed/total:.1f} ç§’/èµ„äº§")
    print("=" * 80)
    
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("  1. è·å–ä¼°å€¼æ•°æ®: python3 fetch_valuation_history.py")
    print("  2. å¯¼å‡ºè¡Œæƒ…æ•°æ®: python3 export_daily_csv.py")
    print("  3. å¯¼å‡ºè´¢åŠ¡æ•°æ®: python3 export_financials_formatted.py")
    print("=" * 80)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
