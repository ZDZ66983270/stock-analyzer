"""
ETL Service (æ•°æ®æ¸…æ´—ä¸å…¥åº“æœåŠ¡)
=============================

åŠŸèƒ½è¯´æ˜:
1. å°† RawMarketData (JSON æ ¼å¼) æ¸…æ´—å¹¶è½¬æ¢ä¸ºç»“æ„åŒ–çš„ MarketDataDaily (å†å²) å’Œ MarketSnapshot (å¿«ç…§)ã€‚
2. è´Ÿè´£æ—¶é—´å½’ä¸€åŒ–ã€å¼‚å¸¸æ•°æ®è¿‡æ»¤ï¼ˆå¦‚ç›˜ä¸­é”™è¯¯å¿«ç…§ï¼‰ä»¥åŠæ ¸å¿ƒæŒ‡æ ‡çš„åˆæ­¥è®¡ç®—ã€‚

æ ¸å¿ƒé€»è¾‘ä¸å…¬å¼:
1. **æ—¶é—´å½’ä¸€åŒ– (Time Normalization)**:
   - æ—¥çº¿æ•°æ®: è‹¥æ—¶é—´ä¸º 00:00:00ï¼Œåˆ™è‡ªåŠ¨å½’ä¸€åŒ–ä¸ºæ”¶ç›˜æ—¶é—´ã€‚
   - å…¬å¼: `Target_Time = Date + Market_Close_Time (US:16:00, HK:16:00, CN:15:00)`
2. **ä»·æ ¼æŒ‡æ ‡è®¡ç®—**:
   - æ¶¨è·Œé¢ (Change): `Price - Previous_Close`
   - æ¶¨è·Œå¹… (Pct Change): `(Change / Previous_Close) * 100`
   - è¯´æ˜: `Previous_Close` ä¼˜å…ˆé€‰ç”¨æ•°æ®æºæä¾›çš„å­—æ®µï¼Œè‹¥ç¼ºå¤±åˆ™ä»æ•°æ®åº“æŸ¥è¯¢ä¸Šä¸€äº¤æ˜“æ—¥è®°å½•ã€‚
3. **å¿«ç…§æ›´æ–°ç­–ç•¥**:
   - ç›˜ä¸­æ—¶æ®µ: æ›´æ–° `MarketSnapshot` çš„æœ€æ–°ä»· and å®æ—¶æ¶¨è·Œå¹…ï¼Œä¸å†™å…¥ `MarketDataDaily`ã€‚
   - ç›˜åæ—¶æ®µ: å¾… ETL å®Œæˆåï¼Œç”¨ `MarketDataDaily` çš„æ ‡å‡†æ”¶ç›˜æ•°æ®åˆ·æ–° `MarketSnapshot`ã€‚

ä½œè€…: Antigravity
æ—¥æœŸ: 2026-01-23
"""

import json
import pandas as pd
import logging
from datetime import datetime, time
from sqlmodel import Session, select, delete
from database import engine
from models import RawMarketData, MarketDataDaily, MarketSnapshot
from market_status import is_market_open
from symbols_config import get_canonical_symbol  # âœ… å¯¼å…¥ç¬¦å·è§„èŒƒåŒ–

logger = logging.getLogger("ETLService")

class ETLService:
    
    @staticmethod
    def process_raw_data(raw_id: int):
        """
        Main Pipeline: Raw -> Clean -> Prod
        """
        with Session(engine) as session:
            # 1. Extract
            raw_record = session.get(RawMarketData, raw_id)
            if not raw_record:
                logger.error(f"Raw record {raw_id} not found")
                return
            
            if raw_record.processed:
                logger.info(f"Raw record {raw_id} already processed")
                return

            # âœ… 2. ç¬¦å·è§„èŒƒåŒ–ï¼š800000â†’HSI, 800700â†’HSTECH
            original_symbol = raw_record.symbol
            canonical_symbol = get_canonical_symbol(original_symbol)
            if canonical_symbol != original_symbol:
                logger.info(f"ç¬¦å·è§„èŒƒåŒ–: {original_symbol} â†’ {canonical_symbol}")
                raw_record.symbol = canonical_symbol

            try:
                payload_data = json.loads(raw_record.payload)
                
                # Handle wrapped payload (e.g. {'symbol':..., 'data': [...]})
                if isinstance(payload_data, dict) and 'data' in payload_data:
                    data_list = payload_data['data']
                elif isinstance(payload_data, list):
                    data_list = payload_data
                else:
                    logger.error(f"Unknown payload format for {raw_id}")
                    return

                if not data_list:
                    raw_record.processed = True
                    session.add(raw_record)
                    session.commit()
                    return

                df = pd.DataFrame(data_list)
                
                # 2. Transform & Load - åŸºäºæ•°æ®ç±»å‹å’Œå¸‚åœºçŠ¶æ€åˆ¤æ–­
                market_is_open = is_market_open(raw_record.market)
                
                if raw_record.period == '1d':
                    # æ—¥çº¿æ•°æ®ï¼šå§‹ç»ˆå°è¯•å¤„ç†ï¼Œå†…éƒ¨ä¼šåˆ¤å®šæ—¥æœŸæ˜¯å¦å·²å®šå‹
                    logger.info(f"Processing 1d record: {raw_record.symbol}")
                    ETLService._process_daily(session, df, raw_record)
                else:
                    # éæ—¥çº¿æ•°æ®ï¼ˆåˆ†é’Ÿ/å®æ—¶ï¼‰ï¼šä¸ä¿å­˜Daily
                    logger.info(f"Intraday/Other data (period={raw_record.period}): skipping Daily table")
                
                # 3. æ€»æ˜¯æ›´æ–°Snapshotï¼ˆæœ€æ–°è¡Œæƒ…ï¼‰
                ETLService._update_snapshot(session, df, raw_record, market_is_open)
                
                # Mark Done
                raw_record.processed = True
                session.add(raw_record)
                session.commit()
                logger.info(f"âœ… ETL Complete for Raw {raw_id} ({raw_record.symbol})")
                
            except Exception as e:
                logger.error(f"ETL Failed for {raw_id}: {e}")
                raw_record.error_log = str(e)
                session.add(raw_record)
                session.commit()

    @staticmethod
    def _process_daily(session: Session, df: pd.DataFrame, meta: RawMarketData):
        """
        Clean Daily Data:
        1. Time Normalization: 00:00:00 -> Market Close Time
        2. Bad Data Filter: Reject 15:59 intraday snapshots
        3. US Market Open Filter: Remove today's data (real-time price with wrong timestamp)
        4. Indicator Calc: Fill missing Change
        """
        # âœ… ç»Ÿä¸€ä½¿ç”¨timestampä½œä¸ºæ—¶é—´å­—æ®µ
        # Field normalizerå°†"æ—¥æœŸ"æ˜ å°„ä¸º"timestamp"ï¼ŒETLå†…éƒ¨ä¹Ÿç»Ÿä¸€ä½¿ç”¨timestamp
        # åªåœ¨ä¿å­˜åˆ°DBæ—¶æ‰æ˜ å°„ä¸º'date'ï¼ˆå…¼å®¹ç°æœ‰schemaï¼‰
        
        # å…¼å®¹æ—§æ•°æ®ï¼šå¦‚æœåªæœ‰dateæ²¡æœ‰timestampï¼Œå¤åˆ¶è¿‡æ¥
        if 'date' in df.columns and 'timestamp' not in df.columns:
            df['timestamp'] = df['date']
        
        # Ensure timestamp type - æ”¯æŒå­—ç¬¦ä¸²å’Œæ¯«ç§’timestamp
        if 'timestamp' in df.columns:
            # æ™ºèƒ½åˆ¤æ–­ï¼šå­—ç¬¦ä¸²ç”¨é»˜è®¤è§£æï¼Œæ•°å€¼ç”¨unit='ms'
            if df['timestamp'].dtype == 'object':  # å­—ç¬¦ä¸²æ ¼å¼ (CN/HK)
                df['timestamp'] = pd.to_datetime(df['timestamp'])
            else:  # æ•°å€¼æ ¼å¼ (USæ¯«ç§’timestamp)
                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        else:
            raise KeyError("'timestamp' column not found in DataFrame")
        
        # åˆ é™¤USå¼€ç›˜è¿‡æ»¤ï¼ˆå†—ä½™é€»è¾‘ï¼‰
        # ETLä¸åº”åˆ¤æ–­å¸‚åœºçŠ¶æ€ï¼Œåº”ç”±è°ƒç”¨æ–¹å†³å®š
        
        # Sort for calculation
        df = df.sort_values('timestamp')
        
        # Pre-fetch last close from DB for continuity
        # âœ… ä¿®å¤ï¼šæŸ¥è¯¢å°äºå½“å‰æ‰¹æ¬¡æœ€å°æ—¥æœŸçš„è®°å½•ï¼Œé¿å…æŸ¥åˆ°å½“å¤©å·²ä¿å­˜çš„è®°å½•
        last_close = None
        if not df.empty:
            # è·å–å½“å‰æ‰¹æ¬¡çš„æœ€å°æ—¥æœŸ
            min_timestamp_in_batch = df['timestamp'].min()
            if pd.notna(min_timestamp_in_batch):
                min_date_str = min_timestamp_in_batch.strftime('%Y-%m-%d %H:%M:%S')
                
                stmt = select(MarketDataDaily).where(
                    MarketDataDaily.symbol == meta.symbol,
                    MarketDataDaily.market == meta.market,
                    MarketDataDaily.timestamp < min_date_str
                ).order_by(MarketDataDaily.timestamp.desc()).limit(1)
                
                prev_rec = session.exec(stmt).first()
                if prev_rec:
                    last_close = prev_rec.close
                    logger.info(f"âœ… Pre-fetched last_close={last_close} for {meta.symbol} (before {min_date_str})")


        record_count = 0  # âœ… æ‰¹é‡æäº¤è®¡æ•°å™¨
        
        # ğŸ§ª è·å–å¸‚åœºå½“å‰æ—¥æœŸç”¨äºè¿‡æ»¤ç›˜ä¸­æœªå®šå‹æ•°æ®
        from market_status import get_market_time, is_market_open, get_market_close_time
        market_now = get_market_time(meta.market)
        market_today = market_now.date()
        market_open = is_market_open(meta.market)
        
        market_close_time = get_market_close_time(meta.market)
        
        # --- ITERATE: Process Each Row ---
        # last_close is already initialized above, no need to reset here
        for _, row in df.iterrows():
            orig_time = row['timestamp']
            
            # --- ğŸ›¡ï¸ GUARD: Only skip "Today" if the market is NOT FINISHED ---
            # Define "Finished": current_time >= close_time OR market is forcibly closed and passed date
            # We are conservative: If date is TODAY, and current_time < close_time, SKIP.
            # Even if market is technically "closed" for lunch, we shouldn't finalize daily data yet.
            if orig_time.date() == market_today and meta.market != 'WORLD':
                current_time = market_now.time()
                is_unfinished_day = False
                
                # Check 1: Is market currently open?
                if market_open:
                    is_unfinished_day = True
                
                # Check 2: Is it before closing time? (e.g. Lunch break or Pre-market)
                elif current_time < market_close_time:
                    is_unfinished_day = True
                
                if is_unfinished_day:
                    logger.info(f"â­ï¸ Skipping Daily storage for {meta.symbol} on {orig_time.date()} (Market OPEN or PRE-CLOSE)")
                    continue
            
            h, m, s = orig_time.hour, orig_time.minute, orig_time.second
                
            # --- TRANSFORM: Time Normalization ---
            # Rule: 00:00:00 -> Market Close Time
            # For daily data from sources like AkShare/yfinance, they often return 00:00:00
            # We need to normalize it to market close time
            target_time = orig_time
            has_time = (h != 0 or m != 0 or s != 0)
            
            # Normalize if time is 00:00:00 (daily data)
            if not has_time:
                if meta.market == 'US':
                    # Set to 16:00 US Eastern
                    target_time = orig_time.replace(hour=16, minute=0, second=0)
                elif meta.market == 'HK':
                    # Set to 16:00 HK Time
                    target_time = orig_time.replace(hour=16, minute=0, second=0)
                elif meta.market == 'CN':
                    # Set to 15:00 Beijing Time
                    target_time = orig_time.replace(hour=15, minute=0, second=0)
            
            # --- CALC: Indicators ---
            close_p = float(row['close'])
            change_p = row.get('change')
            pct_p = row.get('pct_change')
            prev_close_from_row = row.get('prev_close')
            
            # âœ… æ··åˆæ–¹æ¡ˆï¼šå¦‚æœæ•°æ®æºæ²¡æœ‰æä¾›prev_closeï¼Œä»æ•°æ®åº“æŸ¥è¯¢
            if prev_close_from_row is None and close_p is not None:
                try:
                    # å‡†å¤‡æ—¥æœŸå­—ç¬¦ä¸²ç”¨äºæŸ¥è¯¢
                    target_time = orig_time
                    has_time = (orig_time.hour != 0 or orig_time.minute != 0 or orig_time.second != 0)
                    if not has_time:
                        if meta.market == 'US':
                            target_time = orig_time.replace(hour=16, minute=0, second=0)
                        elif meta.market == 'HK':
                            target_time = orig_time.replace(hour=16, minute=0, second=0)
                        elif meta.market == 'CN':
                            target_time = orig_time.replace(hour=15, minute=0, second=0)
                    
                    current_date_str = target_time.strftime('%Y-%m-%d %H:%M:%S')
                    
                    # æŸ¥è¯¢å‰ä¸€æ¡è®°å½•
                    prev_record = session.exec(
                        select(MarketDataDaily)
                        .where(MarketDataDaily.symbol == meta.symbol)
                        .where(MarketDataDaily.market == meta.market)
                        .where(MarketDataDaily.timestamp < current_date_str)
                        .order_by(MarketDataDaily.timestamp.desc())
                    ).first()
                    
                    if prev_record and prev_record.close:
                        prev_close_from_row = prev_record.close
                        logger.info(f"âœ… ä»æ•°æ®åº“è¡¥å…¨prev_close: {meta.symbol} {current_date_str} prev_close={prev_close_from_row}")
                except Exception as e:
                    logger.warning(f"æŸ¥è¯¢prev_closeå¤±è´¥: {e}")
            
            # Calculate if missing (None), don't recalculate if explicitly 0
            # Use prev_close from row (original orè¡¥å…¨from DB) or last_close from iteration
            effective_prev_close = prev_close_from_row if prev_close_from_row is not None else last_close
            
            if (change_p is None or pct_p is None) and effective_prev_close:
                 change_p = close_p - effective_prev_close
                 pct_p = (change_p / effective_prev_close) * 100
                 logger.info(f"ETL Calculated: change={change_p:.2f}, pct={pct_p:.2f}% (prev_close={effective_prev_close:.2f})")
            
            # Prepare Model
            db_date_str = target_time.strftime('%Y-%m-%d %H:%M:%S')
            logger.info(f"ETL Saving {meta.symbol}: target_time={target_time} -> db_date_str={db_date_str} (has_time={has_time})")
            
            # Check exist (Upsert logic)
            # For simplicity in this session, we query-check. In prod, use ON CONFLICT.
            existing = session.exec(select(MarketDataDaily).where(
                MarketDataDaily.symbol == meta.symbol,
                MarketDataDaily.market == meta.market,
                MarketDataDaily.timestamp == db_date_str
            )).first()
            
            if existing:
                # Update
                existing.close = close_p
                existing.change = change_p
                existing.pct_change = pct_p
                existing.prev_close = effective_prev_close  # âœ… ä¿®å¤ï¼šä¹Ÿè¦æ›´æ–°prev_close
                existing.volume = row.get('volume', existing.volume)
                session.add(existing)
            else:
                # Insert
                # âœ… ä¿®å¤ï¼šå¤„ç† Trusts/Mutual Funds åªæœ‰æ”¶ç›˜ä»·çš„æƒ…å†µ (Open/High/Low may be None/NaN)
                def clean_val(val, fallback):
                    if pd.isna(val) or val is None: return fallback
                    return val
                
                safe_open = clean_val(row.get('open'), close_p)
                safe_high = clean_val(row.get('high'), close_p)
                safe_low = clean_val(row.get('low'), close_p)

                # Insert
                new_rec = MarketDataDaily(
                    symbol=meta.symbol,
                    market=meta.market,
                    timestamp=db_date_str,  # âœ… ä¿®å¤ï¼šä½¿ç”¨timestampè€Œédate
                    open=safe_open,
                    high=safe_high,
                    low=safe_low,
                    close=close_p,
                    volume=row.get('volume'),
                    change=change_p,
                    pct_change=pct_p,
                    prev_close=effective_prev_close,
                    updated_at=datetime.now()
                )
                session.add(new_rec)
            
            # âœ… æ‰¹é‡æäº¤ä¼˜åŒ–: æ¯100æ¡æäº¤ä¸€æ¬¡
            record_count += 1
            if record_count % 100 == 0:
                session.commit()
                logger.info(f"ğŸ’¾ Batch commit: {record_count} records processed")
            
            # Update last_close for next iteration
            last_close = close_p
        
        # âœ… æœ€åæäº¤å‰©ä½™è®°å½•
        if record_count % 100 != 0:
            session.commit()
            logger.info(f"ğŸ’¾ Final commit: {record_count} total records")
            
        logger.info(f"Daily ETL: Parsed {len(df)} rows, Upserted {record_count} rows.")


    # MarketDataMinuteå·²åºŸå¼ƒï¼Œåˆ†é’Ÿæ•°æ®å¤„ç†æš‚æ—¶ä¸éœ€è¦
    # å¦‚éœ€æ¢å¤ï¼Œå¯ä»¥é‡æ–°å®ç°åˆ†é’Ÿçº§æ•°æ®å­˜å‚¨
    
    @staticmethod
    def _update_snapshot(session: Session, df: pd.DataFrame, meta: RawMarketData, is_market_open: bool):
        """
        æ›´æ–°MarketSnapshotï¼ˆæœ€æ–°è¡Œæƒ…ï¼‰
        ç›˜ä¸­ï¼šä½¿ç”¨åˆ†é’Ÿæ•°æ®æœ€æ–°ä»·æ ¼
        ç›˜åï¼šä»Dailyè¡¨è¯»å–æ”¶ç›˜ä»·
        """
        try:
            if is_market_open:
                # ç›˜ä¸­ï¼šä½¿ç”¨åˆ†é’Ÿæ•°æ®
                if df.empty:
                    return
                
                latest_row = df.iloc[-1]
                
                # è®¡ç®—æ¶¨è·Œå¹…ï¼ˆåŸºäºå‰ä¸€æ—¥æ”¶ç›˜ï¼‰
                prev_daily = session.exec(
                    select(MarketDataDaily)
                    .where(MarketDataDaily.symbol == meta.symbol)
                    .order_by(MarketDataDaily.timestamp.desc())
                    .limit(1)
                ).first()
                
                prev_close = prev_daily.close if prev_daily else None
                current_price = float(latest_row.get('close', 0))
                change = current_price - prev_close if prev_close else 0
                pct_change = (change / prev_close * 100) if prev_close else 0
                
                snapshot_data = {
                    'price': current_price,
                    'open': float(latest_row.get('open', 0)),
                    'high': float(latest_row.get('high', 0)),
                    'low': float(latest_row.get('low', 0)),
                    'volume': int(latest_row.get('volume', 0)),
                    'change': change,
                    'pct_change': pct_change,
                    'prev_close': prev_close,
                    'date': str(latest_row.get('date', '')),
                    'data_source': 'intraday',
                    'updated_at': datetime.now()
                }
                
                logger.info(f"Updating Snapshot from intraday data: {meta.symbol} = {current_price}")
                
            else:
                # ç›˜åï¼šä»Dailyè¡¨è¯»å–å·²ç»è®¡ç®—å¥½çš„æ•°æ®
                if df.empty:
                    logger.warning(f"Empty dataframe for {meta.symbol}, skipping snapshot update")
                    return
                
                latest_row = df.iloc[-1]
                
                # âœ… ä¿®å¤ï¼šæŸ¥è¯¢Dailyè¡¨çš„æœ€æ–°è®°å½•ï¼Œä½¿ç”¨å…¶ä¸­å·²ç»è®¡ç®—å¥½çš„prev_close/change/pct_change
                latest_daily = session.exec(
                    select(MarketDataDaily)
                    .where(MarketDataDaily.symbol == meta.symbol)
                    .where(MarketDataDaily.market == meta.market)
                    .order_by(MarketDataDaily.timestamp.desc())
                    .limit(1)
                ).first()
                
                # ä¼˜å…ˆä½¿ç”¨Dailyè¡¨ä¸­å·²ç»è®¡ç®—å¥½çš„å€¼
                if latest_daily:
                    current_price = float(latest_daily.close)
                    prev_close = latest_daily.prev_close
                    change = latest_daily.change if latest_daily.change is not None else 0.0
                    pct_change = latest_daily.pct_change if latest_daily.pct_change is not None else 0.0
                    logger.info(f"ä»Dailyè¡¨è¯»å–: {meta.symbol} close={current_price}, prev_close={prev_close}, change={change:.2f}, pct={pct_change:+.2f}%")
                else:
                    # Fallbackï¼šDailyè¡¨æ²¡æœ‰æ•°æ®ï¼Œä»DataFrameè®¡ç®—
                    current_price = float(latest_row.get('close', 0))
                    prev_close = None
                    change = 0.0
                    pct_change = 0.0
                    logger.warning(f"Dailyè¡¨æ— æ•°æ®ï¼Œä½¿ç”¨DataFrame: {meta.symbol} = {current_price}")
                
                snapshot_data = {
                    'price': current_price,
                    'open': float(latest_row.get('open', 0)),
                    'high': float(latest_row.get('high', 0)),
                    'low': float(latest_row.get('low', 0)),
                    'volume': int(latest_row.get('volume', 0)),
                    'change': change,
                    'pct_change': pct_change,
                    'prev_close': prev_close,
                    'timestamp': latest_daily.timestamp if latest_daily else str(latest_row.get('timestamp', '')),  # âœ… ä½¿ç”¨timestamp
                    'data_source': 'daily_close',
                    'updated_at': datetime.now()
                }
                
                logger.info(f"Updating Snapshot from daily data: {meta.symbol} = {current_price} (change={change:.2f}, {pct_change:+.2f}%)")
            
            # Upsert Snapshot
            snapshot = session.exec(
                select(MarketSnapshot)
                .where(
                    MarketSnapshot.symbol == meta.symbol,
                    MarketSnapshot.market == meta.market
                )
            ).first()
            
            if snapshot:
                # æ›´æ–°ç°æœ‰è®°å½•
                for key, value in snapshot_data.items():
                    setattr(snapshot, key, value)
            else:
                # åˆ›å»ºæ–°è®°å½•
                snapshot = MarketSnapshot(
                    symbol=meta.symbol,
                    market=meta.market,
                    **snapshot_data
                )
                session.add(snapshot)
            
            session.commit()
            logger.info(f"âœ… Snapshot updated: {meta.symbol}")
            
        except Exception as e:
            logger.error(f"Failed to update snapshot for {meta.symbol}: {e}")

