"""
VERA Data Fetching Engine (Legacy & Unified Core)
==============================================================================

æœ¬æ¨¡å—æ˜¯ VERA ç³»ç»Ÿçš„æ•°æ®æŠ“å–æ ¸å¿ƒã€‚å®ƒè´Ÿè´£å¯¹æ¥å…¨çƒå¤šä¸ªé‡‘èæ•°æ®æºï¼ˆAkShare, yfinance, FMPï¼‰ï¼Œ
å¹¶é›†æˆäº†å¤æ‚çš„åçˆ¬ã€é™æµã€æ—¶åŒºè½¬æ¢ä»¥åŠå®¹é”™å›é€€æœºåˆ¶ã€‚

æ ¸å¿ƒåŠŸèƒ½:
========================================

I. æ•°æ®æºåˆ†å‘ (Multi-Source Dispatching)
----------------------------------------
1. **CN/HK (Domestic)**: 
   - ä¼˜å…ˆä½¿ç”¨ **AkShare (EastMoney API)** è·å–å®æ—¶è¡Œæƒ…ä¸å†å²æ—¥çº¿ã€‚
   - é’ˆå¯¹å›½å†…åŸŸåï¼ˆ*.eastmoney.comï¼‰å®ç°äº†ç‰¹æ®Šçš„ `NO_PROXY` è‡ªåŠ¨é…ç½®ï¼Œç»•è¿‡ç³»ç»Ÿ VPN ä»¥æå‡ç¨³å®šæ€§ã€‚
2. **US (International)**:
   - ä¼˜å…ˆä½¿ç”¨ **yfinance** è·å–åˆ†é’Ÿçº§ä¸æ—¥çº¿æ•°æ®ã€‚
   - **FMP Cloud**: ç”¨äºè·å–é«˜ä»·å€¼ of US è´¢æŠ¥ï¼ˆå½’æ¯å‡€åˆ©æ¶¦ã€ç¨€é‡Šè‚¡æ•°ã€PIT è´¢æŠ¥æ—¥æœŸï¼‰ã€‚
3. **Indices (Indices)**: ä¸“é—¨ç®¡ç†å…¨çƒæŒ‡æ•°ï¼ˆ^DJI, ^NDX, ^SPX, HSI ç­‰ï¼‰çš„åŒæ­¥é€»è¾‘ã€‚

II. æ™ºèƒ½å†³ç­–æœºåˆ¶ (Orchestration Integration)
----------------------------------------
- ä¸ `DataOrchestrator` é›†æˆï¼šåœ¨å‘èµ·ç½‘ç»œè¯·æ±‚å‰ï¼Œè‡ªåŠ¨åˆ¤æ–­å¸‚åœºçŠ¶æ€ï¼ˆå¼€å¸‚/é—­å¸‚/åˆä¼‘ï¼‰ã€‚
- **Skip Logic**: å¦‚æœå¸‚åœºå·²é—­ç›˜ä¸”æ•°æ®åº“å·²æœ‰ä»Šæ—¥ç»ˆå€¼ï¼Œåˆ™è‡ªåŠ¨è·³è¿‡æŠ“å–ï¼Œç›´æ¥è¿”å›ç¼“å­˜æ•°æ®ã€‚
- **Backfill Integration**: æ”¯æŒè‡ªåŠ¨åŒ–çš„ç¼ºå¤±æ•°æ®è¡¥å¡«é€»è¾‘ï¼ˆBackfill Missing Dataï¼‰ã€‚

III. æ•°æ®æ¸…æ´—ä¸æ ‡å‡†åŒ– (ETL Preparation)
----------------------------------------
- å®ç° `standardize_akshare_fields`: å°† AkShare çš„ä¸­æ–‡å­—æ®µï¼ˆä»Šå¼€ã€æ˜¨æ”¶ç­‰ï¼‰å½’ä¸€åŒ–ä¸ºæ ‡å‡†çš„è‹±æ–‡ Keyã€‚
- å¼•å…¥ `RateLimiter`: é’ˆå¯¹å• symbol å’Œå…¨å±€æ•°æ®æºé¢‘ç‡è¿›è¡Œä¸¥æ ¼é™æµï¼Œé˜²èŒƒ IP å°ç¦ã€‚

ä½œè€…: Antigravity
æ—¥æœŸ: 2026-01-23
"""

import akshare as ak
import pandas as pd
import requests
from typing import Optional, Dict
import sqlite3
import os
import logging # Kept logging as it's used extensively in the class
import time
import threading
import pytz
from datetime import datetime, time as dtime
from sqlalchemy import create_engine
from database import engine
from sqlmodel import Session, select

from models import MarketDataDaily

# âœ… ä½¿ç”¨ç»Ÿä¸€çš„ç¬¦å·è½¬æ¢å·¥å…·
from utils.symbol_utils import normalize_symbol_db, to_akshare_us_symbol, get_market

def calculate_change_pct(current_price: float, prev_close: float, open_price: float = None) -> tuple:
    """
    âš ï¸ DEPRECATED: This function is now handled by ETL Service.
    Use ETL Service for all change/pct_change calculations.
    
    Unified calculation for change amount and percentage change.
    
    Args:
        current_price: Current/latest price
        prev_close: Previous day's closing price
        open_price: Optional, today's opening price (fallback if prev_close is missing)
    
    Returns:
        tuple: (change, pct_change)
        - change: Price difference (rounded to 2 decimals)
        - pct_change: Percentage change (rounded to 2 decimals)
    
    Logic:
        - If prev_close is valid, use it as baseline
        - If prev_close is 0 or None, try to use open_price
        - If both are invalid, return (0.0, 0.0)
    """
    baseline = prev_close
    
    # Fallback to open_price if prev_close is invalid
    if not baseline or baseline == 0:
        if open_price and open_price > 0:
            baseline = open_price
        else:
            return (0.0, 0.0)
    
    change = current_price - baseline
    pct_change = (change / baseline) * 100
    
    return (round(change, 2), round(pct_change, 2))

class DataFetcher:
    def __init__(self, log_dir="logs_V4", output_dir="output_V4"):
        """
        åˆå§‹åŒ–DataFetcher
        
        Args:
            log_dir: æ—¥å¿—ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
        
        Note: symbols_V4.txtå·²åºŸå¼ƒï¼Œè‚¡ç¥¨åˆ—è¡¨ä»æ•°æ®åº“åŠ è½½
        """
        # Make paths absolute relative to this file to avoid CWD issues
        base_dir = os.path.dirname(os.path.abspath(__file__))
        # âš ï¸ DEBUG: æ ‡è®°ä»£ç ç‰ˆæœ¬
        self.CODE_VERSION = "v2.0_smart_period"  # ç‰ˆæœ¬æ ‡è®°
        print(f"[DEBUG] DataFetcher.__init__ called, VERSION={self.CODE_VERSION}")
        
        self.log_dir = os.path.join(base_dir, log_dir)
        self.output_dir = os.path.join(base_dir, output_dir)
        
        # --- FIX: Disable System Proxy for AkShare/CN Data ---
        # User environment likely has a Proxy (VPN) active for Yahoo/US data.
        # But EastMoney (CN/HK data) causes ProxyError or is slow via proxy.
        # We configure 'no_proxy' to force direct connection for domestic domains.
        
        # 1. Unset strictly explicit proxies if they are causing 'Unable to connect' globally
        # But if Yahoo still worked, maybe we SHOULD keep them? 
        # The logs showed ProxyError for EastMoney. 
        # Strategy: Keep proxies generally (if set by system), but BYPASS for specific domains.
        
        # Current code unsets them all. If Yahoo still worked, maybe User has a Transparent Proxy (System VPN) 
        # that doesn't rely on HTTP_PROXY env vars, OR Python isn't picking them up but AkShare for US uses something else?
        # WAIT: The log said "Caused by ProxyError". This proves Python IS trying to use an HTTP Proxy.
        # Implication: My previous `del os.environ` failed to clear it effectively for `requests` on macOS 
        # because `requests` searches macOS system registry via `urllib` if env vars are missing.
        
        # 2. Force NO_PROXY for EastMoney
        no_proxy_domains = [
            "eastmoney.com", "push2his.eastmoney.com", "quote.eastmoney.com", "*.eastmoney.com",
            "gtimg.cn", "sinajs.cn", "163.com", "baidu.com"
        ]
        
        # Append to existing no_proxy or create new
        current_no_proxy = os.environ.get("no_proxy", "")
        # Normalize
        if current_no_proxy:
            current_no_proxy += ","
        
        os.environ["no_proxy"] = current_no_proxy + ",".join(no_proxy_domains)
        os.environ["NO_PROXY"] = os.environ["no_proxy"]
        
        print(f"DEBUG: Configured no_proxy for CN domains: {os.environ['no_proxy']}")
        # ----------------------------------------------------

        self.est_tz = pytz.timezone('Asia/Shanghai')
        print(f"DEBUG: Initializing DataFetcher. Log dir: {self.log_dir}")
        self._setup_logger()
        self.symbols = self._load_symbols()
        
        # --- Bulk Fetch Cache & Safety ---
        self._snapshot_cache: Dict[str, dict] = {} # market -> {symbol_base: row_data}
        # 5. Internal State
        self.market_snapshots = {}  # { market: (data_dict, timestamp) }
        self.snapshot_cache_duration = 60  # seconds
        
        # 6. Rate Limiter - é˜²æ­¢è¢«æ‹‰é»‘
        from rate_limiter import get_rate_limiter
        self.rate_limiter = get_rate_limiter()
        self.logger.info("Rate Limiter initialized: 10s symbol interval, 5 requests/minute")
        
        self._snapshot_time: Dict[str, float] = {} # market -> timestamp
        self._snapshot_lock = threading.Lock()
    
    def standardize_akshare_fields(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ç»Ÿä¸€AkShareå­—æ®µå‘½å
        æ‰€æœ‰AkShareæ¥å£éƒ½ä½¿ç”¨'date'æˆ–'æ—¥æœŸ'ä½œä¸ºæ—¶é—´å­—æ®µï¼Œéœ€è¦ç»Ÿä¸€è½¬æ¢ä¸º'timestamp'
        """
        if df is None or df.empty:
            return df
        
        # 1. ç»Ÿä¸€æ—¶é—´å­—æ®µä¸ºtimestamp
        if 'timestamp' not in df.columns:
            for time_field in ['date', 'æ—¥æœŸ', 'æ—¶é—´']:
                if time_field in df.columns:
                    df['timestamp'] = pd.to_datetime(df[time_field])
                    self.logger.debug(f"Standardized time field: {time_field} â†’ timestamp")
                    break
        
        # 2. ç»Ÿä¸€ä¸­æ–‡å­—æ®µä¸ºè‹±æ–‡ï¼ˆå¦‚æœè¿˜æ²¡è½¬æ¢ï¼‰
        field_mapping = {
            'å¼€ç›˜': 'open',
            'æ”¶ç›˜': 'close', 
            'æœ€é«˜': 'high',
            'æœ€ä½': 'low',
            'æˆäº¤é‡': 'volume',
            'æˆäº¤é¢': 'turnover'
        }
        
        for cn_field, en_field in field_mapping.items():
            if cn_field in df.columns and en_field not in df.columns:
                df[en_field] = df[cn_field]
        
        return df

    
    def is_market_open_with_tz(self, market: str) -> bool:
        """
        âš ï¸ DEPRECATED: Use market_status.is_market_open() instead.
        
        åˆ¤æ–­å¸‚åœºæ˜¯å¦å¼€å¸‚ï¼ˆè€ƒè™‘æ—¶åŒºï¼‰
        
        Args:
            market: å¸‚åœºä»£ç  (CN/HK/US)
        
        Returns:
            True: å¼€å¸‚æœŸé—´ï¼ˆå«ç›˜å‰ç›˜åï¼‰â†’ ä¿å­˜åˆ°MarketDataMinute
            False: é—­å¸‚ â†’ ä¿å­˜åˆ°MarketDataDaily
        """
        import warnings
        warnings.warn(
            "is_market_open_with_tz() is deprecated. Use market_status.is_market_open() instead.",
            DeprecationWarning,
            stacklevel=2
        )
        from market_status import is_market_open
        return is_market_open(market)
        try:
            from market_schedule import MarketSchedule, MarketStatus
            
            status = MarketSchedule.get_status(market)
            
            # OPEN, PRE_MARKET, POST_MARKETéƒ½ç®—å¼€å¸‚æœŸé—´ï¼Œä½¿ç”¨åˆ†é’Ÿæ•°æ®
            is_open = status in [MarketStatus.OPEN, MarketStatus.PRE_MARKET, MarketStatus.POST_MARKET]
            
            self.logger.info(f"{market} market status: {status.value}, is_open={is_open}")
            return is_open
            
        except Exception as e:
            self.logger.error(f"Failed to get market status for {market}: {e}")
            # é»˜è®¤è¿”å›Falseï¼ˆé—­å¸‚ï¼‰ï¼Œä½¿ç”¨Dailyè¡¨æ›´å®‰å…¨
            return False
        
    def _get_safe_delay(self):
        """Random delay to prevent anti-scraping triggers"""
        import random
        return random.uniform(0.5, 2.0)

    def _setup_logger(self):
        os.makedirs(self.log_dir, exist_ok=True)
        log_file = os.path.join(self.log_dir, f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_V4.log")
        logging.basicConfig(
            filename=log_file,
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        console = logging.StreamHandler()
        console.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        console.setFormatter(formatter)
        # Check if handler already exists to avoid duplicates in re-eintrant cases
        if not logging.getLogger().handlers:
            logging.getLogger().addHandler(console)
        self.logger = logging.getLogger(__name__)

    def _load_symbols(self) -> list:
        """
        ä»æ•°æ®åº“åŠ è½½è‚¡ç¥¨åˆ—è¡¨
        
        æ¥æº:
        1. Watchlistè¡¨ - ç”¨æˆ·è‡ªé€‰è‚¡
        2. symbols_config - ç³»ç»ŸæŒ‡æ•°
        
        Note: symbols_V4.txtå·²åºŸå¼ƒ
        """
        symbols = set()
        
        try:
            from database import engine
            from models import Watchlist
            from sqlmodel import Session, select
            from symbols_config import get_all_indices
            
            with Session(engine) as session:
                # 1. ç”¨æˆ·è‡ªé€‰è‚¡
                db_symbols = session.exec(select(Watchlist.symbol)).all()
                for s in db_symbols:
                    symbols.add(s)
                
                # 2. ç³»ç»ŸæŒ‡æ•°
                indices = get_all_indices()
                for idx in indices:
                    symbols.add(idx)
                    
        except Exception as e:
            self.logger.error(f"Error loading symbols from DB: {str(e)}")

        self.logger.info(f"Loaded {len(symbols)} symbols from database (watchlist + indices)")
        return list(symbols)



    def fetch_us_min_data(self, symbol: str) -> pd.DataFrame:
        """
        Fetch US minute data. Priority: yfinance (reliable) > AkShare (fallback)
        """
        try:
            self.logger.info(f"Fetching US minute data for {symbol} (yfinance primary)...")
            
            # PRIMARY: Try yfinance first (more reliable)
            df = self._fetch_fallback_yfinance_min(symbol, "US")
            if df is not None and not df.empty:
                self.logger.info(f"US minute data fetched via yfinance: {len(df)} records")
                return df
            
            # FALLBACK: Try AkShare if yfinance fails
            self.logger.warning(f"yfinance failed for US {symbol}, trying AkShare...")
            # é™æµ
            self.rate_limiter.wait_if_needed(symbol, 'akshare')
            df = ak.stock_us_hist_min_em(symbol=symbol)
            if df is not None and not df.empty:
                df = self.standardize_akshare_fields(df)
                if 'timestamp' in df.columns:
                    df['æ—¥æœŸ'] = df['timestamp'].dt.date
                last_date = df['æ—¥æœŸ'].max()
                first_date = last_date - pd.Timedelta(days=29)
                df = df[df['æ—¥æœŸ'] >= first_date]
                df = df.drop(columns=['æ—¥æœŸ'])
                self.logger.info(f"US minute data fetched via AkShare: {len(df)} records")
                return df
            
            self.logger.error(f"Both yfinance and AkShare failed for US {symbol}")
            return pd.DataFrame()
            
        except Exception as e:
            self.logger.error(f"Error fetching US minute data for {symbol}: {str(e)}")
            return pd.DataFrame()

    def fetch_hk_min_data(self, symbol: str, period: str = '1') -> pd.DataFrame:
        """
        Fetch HK minute data. Priority: yfinance (reliable) > AkShare (fallback)
        """
        try:
            self.logger.info(f"Fetching HK minute data for {symbol} (yfinance primary)...")
            
            # PRIMARY: Try yfinance first
            # User requested skip Yahoo (2025-12-15)
            # df = self._fetch_fallback_yfinance_min(symbol, "HK")
            # if df is not None and not df.empty:
            #     self.logger.info(f"HK minute data fetched via yfinance: {len(df)} records")
            #     return df
            
            # FALLBACK: Try AkShare
            self.logger.warning(f"yfinance failed for HK {symbol}, trying AkShare...")
            code = symbol.replace('.hk', '').replace('.HK', '').zfill(5)
            # é™æµ
            self.rate_limiter.wait_if_needed(symbol, 'akshare')
            df = ak.stock_hk_hist_min_em(symbol=code, period=period)
            if df is not None and not df.empty:
                df = self.standardize_akshare_fields(df)
                self.logger.info(f"HK minute data fetched via AkShare: {len(df)} records")
                return df
            
            self.logger.error(f"Both yfinance and AkShare failed for HK {symbol}")
            return pd.DataFrame()
            
        except Exception as e:
            self.logger.error(f"Error fetching HK minute data for {symbol}: {str(e)}")
            return pd.DataFrame()

    def fetch_cn_min_data(self, symbol: str, period: str = '1') -> pd.DataFrame:
        """
        Fetch CN minute data. Priority: yfinance (reliable) > AkShare (fallback)
        """
        try:
            self.logger.info(f"Fetching CN minute data for {symbol} (yfinance primary)...")
            
            # PRIMARY: Try yfinance first
            df = self._fetch_fallback_yfinance_min(symbol, "CN")
            if df is not None and not df.empty:
                self.logger.info(f"CN minute data fetched via yfinance: {len(df)} records")
                return df
            
            # FALLBACK: Try AkShare
            self.logger.warning(f"yfinance failed for CN {symbol}, trying AkShare...")
            code = symbol.replace('.sh', '').replace('.SH', '').replace('.sz', '').replace('.SZ', '').zfill(6)
            # é™æµ
            self.rate_limiter.wait_if_needed(symbol, 'akshare')
            df = ak.stock_zh_a_hist_min_em(symbol=code, period=period)
            if df is not None and not df.empty:
                df = self.standardize_akshare_fields(df)
                self.logger.info(f"CN minute data fetched via AkShare: {len(df)} records")
                return df
            
            self.logger.error(f"Both yfinance and AkShare failed for CN {symbol}")
            return pd.DataFrame()
            
        except Exception as e:
            self.logger.error(f"Error fetching CN minute data for {symbol}: {str(e)}")
            return pd.DataFrame()

    def fetch_cn_spot_data(self, symbol: str) -> dict:
        """
        Fetch real-time spot data for a single CN stock to get indicators like Dividend Yield, PE, PB.
        Returns a dict with keys: price, open, high, low, volume, amount, pe, pb, dividend_yield, market_cap.
        """
        try:
            code = symbol.replace('.sh', '').replace('.sz', '').zfill(6)
            # Use stock_zh_a_spot_em for full market spot might be slow if fetching all, 
            # but AkShare/EM doesn't have a fast single-stock spot endpoint with indicators easily?
            # stock_individual_info_em gets static info.
            # stock_zh_a_spot_em() returns ALL stocks. Too slow (~5000 rows).
            # Alternative: stock_zh_a_hist_pre_min_em (realtime minute) doesn't have PE/Div.
            # Use 'stock_financial_abstract' for financial info? Only gives static.
            
            # BEST WAY: Use stock_zh_a_spot_em but filter? No, API downloads all.
            # OPTION 2: Use `stock_individual_info_em` for Name/Sector, but not dynamic price indicators.
            # OPTION 3: web scraping specific EM page. 
            # OPTION 4: AkShare has `stock_zh_index_spot_em`? No.
            
            # FASTEST for Single Stock Realtime with PE/PB:
            # Maybe just use `fetch_latest_data` (minute) for Price/Vol, 
            # and use a separate method for static/daily-update indicators like PE/Div?
            
            # For now, let's use the efficient approach:
            # If we need Dividend/PE, we might have to accept they are 'Daily' indicators.
            # `stock_zh_a_indicators` (PE/PB/Div history).
            
            # Let's try `stock_zh_a_spot_em` but cached? No.
            # Wait, `ak.stock_zh_a_spot_em` is surprisingly fast sometimes.
            # But let's check `ak.stock_zh_a_hist` (daily) - does headers have it? No.
            
            # Let's use `ak.stock_a_indicator_lg` (Legu)? No.
            
            # Let's fallback to scraping a lightweight endpoint if possible, or use yfinance for indicators?
            # yfinance info has 'dividendYield'.
            pass
        except:
            pass
        return {}

    def fetch_market_snapshot(self, market: str) -> dict:
        """
        Fetch a full market snapshot with caching (TTL 30s).
        Returns dict: {symbol_base: row_data}
        Currently only implements Stub or simple cache logic.
        """
        # For V4, we might not have a full market snapshot ready for US/HK.
        # So we return empty dict to force fallback to individual fetch.
        return {}

    def fetch_snapshot(self, symbol: str, market: str) -> dict:
        """
        Get a real-time snapshot including Valuation Indicators if possible.
        """
        try:
            # 1. Basic Price/Vol from Min Data (Fast & Reliable)
            base_data = self.fetch_latest_data(symbol, market)
            if not base_data: return None
            
            # 2. Indicators (PE, DIV)
            # For CN, we can try yfinance for indicators as a fallback, 
            # or use AkShare `stock_zh_a_valuation_baostock` (history).
            # Hack: Return base_data and let frontend use historical PE/Div from DB if today's is missing.
            # Ref: User complained Dividend is wrong. DB likely has None.
            # We NEED to fetch valid Dividend.
            
            # Try fetching "stock_zh_a_daily" (qfq) - does it have PE? No.
            # Try "stock_zh_a_daily_indicator" ?
            
            return base_data
        except Exception as e:
            self.logger.error(f"Snapshot error: {e}")
            return None

    def check_market_status(self, market: str) -> bool:
        """
        âš ï¸ DEPRECATED: Use market_status.is_market_open() instead.
        
        Check if the market is currently open.
        Returns True if Open, False if Closed.
        """
        import warnings
        warnings.warn(
            "check_market_status() is deprecated. Use market_status.is_market_open() instead.",
            DeprecationWarning,
            stacklevel=2
        )
        from market_status import is_market_open
        return is_market_open(market)
        from datetime import datetime, time
        import pytz

        now = datetime.now(pytz.timezone('Asia/Shanghai')) # User is likely in China
        
        current_time = now.time()

        if market == "CN":
            # Weekends
            if now.weekday() >= 5: return False
            
            # 9:30-11:30, 13:00-15:00
            morning_open = time(9, 30)
            morning_close = time(11, 30)
            afternoon_open = time(13, 0)
            afternoon_close = time(15, 0)
            return (morning_open <= current_time <= morning_close) or \
                   (afternoon_open <= current_time <= afternoon_close)

        elif market == "HK":
            # Weekends
            if now.weekday() >= 5: return False
            
            # 9:30-12:00, 13:00-16:00
            morning_open = time(9, 30)
            morning_close = time(12, 0)
            afternoon_open = time(13, 0)
            afternoon_close = time(16, 0)
            return (morning_open <= current_time <= morning_close) or \
                   (afternoon_open <= current_time <= afternoon_close)

        elif market == "US":
            # US Eastern Time: 9:30 - 16:00
            # Convert Shanghai 'now' to US/Eastern
            us_tz = pytz.timezone('US/Eastern')
            us_now = now.astimezone(us_tz)
            
            # US verify Weekday
            # US verify Weekday
            if us_now.weekday() >= 5: return False
            
            us_time = us_now.time()
            market_open = time(9, 30)
            market_close = time(16, 0)
            return (market_open <= us_time < market_close)  # 16:00å·²é—­å¸‚

        return True # Default to Open if unknown

    def fetch_latest_data(self, symbol: str, market: str, save_db: bool = True, force_refresh: bool = False) -> dict:
        """
        Orchestrates fetching the absolute latest data.
        Strategy:
        1. Snapshot (All Markets) - fast, efficient.
        2. Database (If Market Closed & Cached)
        3. Realtime API (If Open/Forced)
        """
        try:
            # 0. Check valid market
            if market == 'Other':
                return None
            # Ensure necessary imports for DB operations
            from models import MarketDataDaily
            from database import create_db_and_tables
            from sqlmodel import Session, create_engine, select
            from datetime import datetime, timedelta, time as dtime # dtime for clarity with time objects
            import pytz
            import logging # For logging.info

            # Initialize engine if not already done (assuming self.engine might not exist yet)
            if not hasattr(self, 'engine') or self.engine is None:
                self.engine = create_engine("sqlite:///database.db")
                create_db_and_tables() # Ensure tables exist

            # âœ… ä½¿ç”¨ç»Ÿä¸€çš„å¸‚åœºçŠ¶æ€æ¨¡å—
            from market_status import is_market_open
            is_open = is_market_open(market)
            is_trading_day = (datetime.now().weekday() < 5)  # Monday=0, Sunday=6
            reason = "Unknown" # Legacy support
            self.logger.info(f"Checking {symbol} ({market}): is_open={is_open}, is_trading_day={is_trading_day}")

            # ============================================================
            # ğŸ¯ ä½¿ç”¨ DataOrchestrator è¿›è¡Œç»Ÿä¸€å†³ç­–
            # ============================================================
            from data_orchestrator import DataOrchestrator
            from utils.symbol_utils import normalize_symbol_db
            
            orchestrator = DataOrchestrator()
            db_latest_date = orchestrator.get_db_latest_date(symbol, market)
            
            decision = orchestrator.decide_fetch_strategy(
                symbol=symbol,
                market=market,
                force_refresh=force_refresh,
                db_latest_date=db_latest_date
            )
            
            self.logger.info(
                f"[DataOrchestrator] {symbol} ({market}): "
                f"å†³ç­–={decision.fetch_type}, åŸå› ={decision.reason}"
            )
            
            # å¦‚æœå†³ç­–æ˜¯è·³è¿‡,ç›´æ¥ä»æ•°æ®åº“è¿”å›
            if decision.fetch_type == 'skip':
                self.logger.info(f"[è·³è¿‡] {symbol}: {decision.reason}")
                # ä»æ•°æ®åº“è¿”å›æœ€æ–°æ•°æ®
                from models import MarketSnapshot
                from database import engine
                
                with Session(engine) as session:
                    db_symbol = normalize_symbol_db(symbol, market)
                    snapshot = session.exec(
                        select(MarketSnapshot).where(
                            MarketSnapshot.symbol == db_symbol,
                            MarketSnapshot.market == market
                        )
                    ).first()
                    
                    if snapshot and snapshot.price and snapshot.price > 0:
                        return {
                            'symbol': snapshot.symbol,
                            'market': snapshot.market,
                            'price': snapshot.price,
                            'close': snapshot.price,
                            'open': snapshot.open or 0,
                            'high': snapshot.high or 0,
                            'low': snapshot.low or 0,
                            'prev_close': snapshot.prev_close,
                            'change': snapshot.change or 0,
                            'pct_change': snapshot.pct_change or 0,
                            'volume': snapshot.volume or 0,
                            'turnover': snapshot.turnover,
                            'date': snapshot.date,
                            'pe': snapshot.pe,
                            'pb': snapshot.pb,
                            'dividend_yield': snapshot.dividend_yield,
                            'market_cap': snapshot.market_cap
                        }
                    else:
                        self.logger.warning(f"[è·³è¿‡] {symbol}: DBæ— æœ‰æ•ˆæ•°æ®,ç»§ç»­APIè¯·æ±‚")
            
            # ğŸ”¥ è‡ªåŠ¨å›å¡«å†å²æ•°æ®
            if decision.need_backfill_daily:
                self.logger.info(
                    f"[å†å²è¡¥å……] {symbol}: {decision.backfill_date_range}, "
                    f"åŸå› ={decision.backfill_reason}"
                )
                try:
                    # ç«‹å³è¡¥å……ç¼ºå¤±çš„å†å²æ•°æ®
                    backfill_result = self.backfill_missing_data(symbol, market, days=30)
                    if backfill_result.get('success'):
                        self.logger.info(
                            f"âœ… [{symbol}] å†å²æ•°æ®è¡¥å……æˆåŠŸ: "
                            f"{backfill_result.get('records_fetched', 0)}æ¡è®°å½•"
                        )
                    else:
                        self.logger.warning(
                            f"âš ï¸ [{symbol}] å†å²æ•°æ®è¡¥å……å¤±è´¥: "
                            f"{backfill_result.get('message', 'æœªçŸ¥é”™è¯¯')}"
                        )
                except Exception as e:
                    self.logger.error(f"âŒ [{symbol}] å†å²æ•°æ®è¡¥å……å¼‚å¸¸: {e}")
            
            
            # --- æ—§çš„HKæŒ‡æ•°ç‰¹æ®Šå¤„ç†å·²ç§»é™¤ï¼Œç°åœ¨ä½¿ç”¨ç»Ÿä¸€æ¶æ„ï¼ˆLine 774+ï¼‰---
            
            # âœ… FIX 2025-12-20: US Indicesåº”è¯¥ä½¿ç”¨yfinanceå¢é‡è·å–ï¼Œä¸å†è·¯ç”±åˆ°AkShare
            # åŸå› ï¼šAkShareçš„stock_us_dailyä¼šè¿”å›å…¨é‡å†å²æ•°æ®ï¼ˆ5530æ¡ï¼‰ï¼Œ
            # è€Œyfinanceåœ¨Line 916é…åˆHOTFIX period=5dåªè·å–5å¤©æ•°æ®
            # ğŸ”´ DISABLED: US Indices via AkShare routing (Line 612-665) ğŸ”´
            # --- PRIORITY: US Indices via AkShare (é¿å…è¢«yahooæ‹‰é»‘) ---
            # from symbols_config import is_index, get_akshare_symbol
            # if market == 'US' and is_index(symbol):
            #     self.logger.info(f"Routing US index {symbol} to AkShare...")
            #     
            #     # é™æµï¼šåŒsymbol 10ç§’é—´éš”ï¼Œakshareæºæ¯åˆ†é’Ÿ5è¯·æ±‚
            #     wait_time = self.rate_limiter.wait_if_needed(symbol, 'akshare')
            #     if wait_time > 0:
            #         self.logger.info(f"Rate limit: waited {wait_time:.2f}s for {symbol}")
            #     
            #     try:
            #         import akshare as ak
            #         from datetime import datetime
            #         
            #         ak_symbol = get_akshare_symbol(symbol)  # ^DJI -> .DJI
            #         self.logger.info(f"Fetching {ak_symbol} via ak.stock_us_daily...")
            #         
            #         df = ak.stock_us_daily(symbol=ak_symbol, adjust="")
            #         if df is not None and not df.empty:
            #                 # ğŸ”¥ æ–°æ¶æ„ï¼šä½¿ç”¨ç»Ÿä¸€çš„ETLæµç¨‹
            #                 # ä¸å†ç›´æ¥ä¿å­˜åˆ°Daily/Snapshotï¼Œè€Œæ˜¯ä¿å­˜åˆ°RawMarketData
            #                 if save_db:
            #                     self.logger.info(f"Saving {symbol} to RawMarketData for ETL processing")
            #                     # save_to_db(symbol, market, period_data)
            #                     # period_data = {period: dataframe}
            #                     self.save_to_db(symbol, market, {'1d': df})
            #                 
            #                 # æ„é€ è¿”å›å­—å…¸ï¼ˆç”¨äºè¿”å›ç»™è°ƒç”¨è€…ï¼‰
            #                 latest = df.iloc[-1]
            #                 result = {
            #                     'symbol': symbol,
            #                     'price': float(latest['close']),
            #                     'close': float(latest['close']),
            #                     'open': float(latest['open']),
            #                     'high': float(latest['high']),
            #                     'low': float(latest['low']),
            #                     'volume': int(latest['volume']) if latest['volume'] > 0 else 0,
            #                     'date': f"{latest['date'].strftime('%Y-%m-%d')} 16:00 ç¾ä¸œ",
            #                     'market': market,
            #                 }
            #                 
            #                 # è®¡ç®—æ¶¨è·Œï¼ˆç”¨äºè¿”å›å€¼ï¼‰
            #                 if len(df) >= 2:
            #                     prev = df.iloc[-2]
            #                     result['change'] = result['close'] - float(prev['close'])
            #                     result['pct_change'] = (result['change'] / float(prev['close'])) * 100 if prev['close'] > 0 else 0
            #                 
            #                 self.logger.info(f"âœ… AkShare: {symbol} ${result['price']:.2f} (via ETL)")
            #                 return result
            #             else:
            #                 self.logger.warning(f"AkShare returned empty for {ak_symbol}")
            #         except Exception as ak_err:
            #             self.logger.error(f"AkShare failed for {symbol}: {ak_err}, falling back to yfinance")
            #             # Fall through to yfinance fallback

            # --- STRATEGY 1: Use Bulk Spot Snapshot (Preferred) ---
            # Extract basic code
            base_symbol = symbol.split('.')[0]
            if market == 'US':
                # Remove numeric prefix like "105." or "106."
                if '.' in symbol and symbol.split('.')[0].isdigit():
                     yahoo_symbol = symbol.split('.')[-1]
                else:
                     yahoo_symbol = symbol
                
                # Special case for Indices if needed, but standard stocks are just ticker
                pass
            
            # Fetch (or get cached) snapshot
            snapshot = self.fetch_market_snapshot(market)
            
            if snapshot and base_symbol in snapshot:
                row = snapshot[base_symbol]
                self.logger.info(f"Hit Snapshot for {symbol}")
                
                # Map fields
                try:
                    # EastMoney Logic (CN/HK/US now unified)
                    price = float(row.get('æœ€æ–°ä»·', 0))
                    change = float(row.get('æ¶¨è·Œé¢', 0))
                    pct_change = float(row.get('æ¶¨è·Œå¹…', 0))
                    
                    vol_raw = row.get('æˆäº¤é‡', 0)
                    vol = int(vol_raw) if vol_raw else 0
                    turnover = float(row.get('æˆäº¤é¢', 0) or 0)
                    
                    open_p = float(row.get('ä»Šå¼€', 0) or 0)
                    high_p = float(row.get('æœ€é«˜', 0) or 0)
                    low_p = float(row.get('æœ€ä½', 0) or 0)
                    prev_c = float(row.get('æ˜¨æ”¶', 0) or 0)
                    
                    # Date - Live!
                    now_str = datetime.now(self.est_tz).strftime('%Y-%m-%d %H:%M')
                    if market == 'US':
                         now_str = datetime.now().strftime('%Y-%m-%d %H:%M') + " ç¾ä¸œ(Live)"

                    return {
                        "symbol": symbol,
                        "market": market,
                        "price": price,
                        "close": price,
                        "change": change,
                        "pct_change": pct_change,
                        "volume": int(vol),
                        "turnover": turnover,
                        "date": now_str,
                        "open": open_p,
                        "high": high_p,
                        "low": low_p,
                        "prev_close": prev_c
                    }
                except Exception as map_err:
                    self.logger.error(f"Mapping snapshot failed for {symbol}: {map_err}")

            # --- STRATEGY 2: Fallback to Old Logic (Min/Daily) ---
            # If snapshot missing or symbol not in snapshot
            
            # 2. Database Strategy - IMPROVED for Lunch Break
            # Priority:
            # 1. If trading day (includes lunch break): Try to get today's minute data from DB first
            # 2. If not trading day OR force_refresh: Fetch from API
            # 3. If market closed and we have data: Return cached
            
            # Helper to check DB
            with Session(self.engine) as session:
                # Check daily data (MarketDataMinute table has been removed)
                latest_db = session.exec(
                    select(MarketDataDaily)
                    .where(MarketDataDaily.symbol == symbol)
                    .order_by(MarketDataDaily.date.desc())
                    .limit(1)
                ).first()

                if latest_db:
                    # Logic: If Closed, and we have recent data (e.g. from today or yesterday), return it.
                    # Simple heuristic: If market closed, and we have ANY data from last 24h, good enough?
                    # Or compare date?
                    # Let's simplify: If not force_refresh AND not is_open: Return DB
                    # User requirement: "Refresh time... if Closed... return Last Close".
                    # Even if user pressed Refresh, if it's Closed and we have data, we shouldn't fetch.
                    
                    db_date_str = str(latest_db.date).split(' ')[0] # YYYY-MM-DD
                    today_str = datetime.now().strftime("%Y-%m-%d")
                    
                    # If Market Closed (not even trading day) and we have data
                    if not is_trading_day and not force_refresh:
                        self.logger.info(f"Market Closed (not trading day). DB Record found: {db_date_str}. Returning Cached.")
                        # Convert DB model to Dict
                        # Fix 00:00 Time Display:
                        base_date = db_date_str
                        date_str = ""
                        if market == "CN":
                            date_str = f"{base_date} 15:00"
                        elif market == "HK":
                            date_str = f"{base_date} 16:00"
                        elif market == "US":
                            date_str = f"{base_date} 16:00:00" # Local ET close time usually. 
                        
                        # Ensure we populate MarketSnapshot even if debouncing
                        cached_data = {
                            "symbol": latest_db.symbol,
                            "price": latest_db.close, # In MarketData, close is price
                            "change": latest_db.change,
                            "pct_change": latest_db.pct_change,
                            "volume": latest_db.volume,
                            "market": latest_db.market,
                            "date": date_str, # Use formatted date_str
                            "pe": latest_db.pe,
                            "dividend_yield": latest_db.dividend_yield,
                            # Add other fields if needed, or rely on frontend fallbacks
                            "open": latest_db.open,
                            "high": latest_db.high,
                            "low": latest_db.low,
                            "close": latest_db.close,
                            "prev_close": latest_db.prev_close,
                             # Mark as cached
                            "data_source": "cache_db"
                        }
                        
                        # âœ… Snapshotç”±ETLç®¡ç†ï¼Œä¸åœ¨æ­¤å¤„ç›´æ¥ä¿å­˜
                        # å¦‚æœSnapshotç¼ºå¤±ï¼Œåº”é€šè¿‡ETLé‡å»ºè€Œéç»•è¿‡ETL

                        return cached_data

            # 3. Fetch from API (If Open or DB Missing/Forced Refresh)
            self.logger.info(f"Fetching API for {symbol} (Force: {force_refresh}, Open: {is_open})")
            
            df = pd.DataFrame()
            
            # STRATEGY: ä¼˜å…ˆè·å–æ—¥çº¿æ•°æ®ï¼Œå¤±è´¥æ‰ç”¨åˆ†é’Ÿæ•°æ®
            if market == "CN":
                # 1. ä¼˜å…ˆï¼šæ—¥çº¿æ•°æ®
                try:
                    import akshare as ak
                    from symbols_config import get_akshare_symbol, is_index
                    
                    # âœ… ä½¿ç”¨é›†ä¸­åŒ–çš„symbolæ˜ å°„
                    if is_index(symbol):
                        # æŒ‡æ•°ï¼šä½¿ç”¨get_akshare_symbolè·å–æ­£ç¡®çš„ä»£ç 
                        # ä¾‹å¦‚ï¼š000001.SS â†’ sh000001 (ä¸Šè¯æŒ‡æ•°)
                        akshare_code = get_akshare_symbol(symbol)
                        self.logger.info(f"Fetching CN index {symbol} using AkShare code: {akshare_code}")
                        df_daily = ak.stock_zh_index_daily(symbol=akshare_code)
                    else:
                        # ä¸ªè‚¡ï¼šæå–ä»£ç 
                        code = symbol.split('.')[0]
                        self.logger.info(f"Fetching CN stock {symbol} (code: {code})")
                        self.rate_limiter.wait_if_needed(symbol, 'akshare')
                        df_daily = ak.stock_zh_a_hist(symbol=code, period="daily", adjust="")
                    
                    if df_daily is not None and not df_daily.empty:
                        # åªå–æœ€æ–°ä¸€å¤©çš„æ•°æ®
                        df = df_daily.tail(1).copy()
                        # âœ… ä½¿ç”¨ç»Ÿä¸€çš„å­—æ®µæ ‡å‡†åŒ–
                        df = self.standardize_akshare_fields(df)
                        # âœ… æ•°æ®ä¿æŒåŸå§‹æ—¶é—´ï¼Œä¸å†å¼ºåˆ¶ä¿®æ”¹
                        # æ—¶é—´æˆ³å°†ç”±ä¿å­˜é€»è¾‘æ ¹æ®å¸‚åœºçŠ¶æ€é€‰æ‹©åˆé€‚çš„è¡¨
                        
                        self.logger.info(f"âœ… CN daily data fetched: {df['timestamp'].iloc[0]}")
                    else:
                        raise Exception("Daily data empty")
                        
                except Exception as daily_err:
                    # 2. Fallbackï¼šåˆ†é’Ÿæ•°æ®
                    self.logger.warning(f"CN daily data failed ({daily_err}), falling back to minute data...")
                    df = self.fetch_cn_min_data(symbol, period='1')
                    
            elif market == "HK":
                # === HKå¸‚åœºï¼šåŒºåˆ†æŒ‡æ•°å’Œä¸ªè‚¡ ===
                from symbols_config import is_index
                
                if is_index(symbol):
                    # --- HKæŒ‡æ•°åˆ†æ”¯ ---
                    self.logger.info(f"HK Index detected: {symbol}")
                    
                    # åˆ¤æ–­å¸‚åœºçŠ¶æ€ï¼ˆç»Ÿä¸€æ¶æ„ï¼‰
                    if is_open:
                        # å¼€å¸‚ï¼šè·å–å®æ—¶æ•°æ®
                        self.logger.info(f"HK market OPEN: fetching realtime for index {symbol}")
                        latest_data = self.fetch_hk_index_realtime(symbol)
                        
                    else:
                        # é—­å¸‚ï¼šè·å–æ—¥çº¿æ•°æ®å¹¶ä½¿ç”¨ç»Ÿä¸€ETLæµç¨‹
                        self.logger.info(f"HK market CLOSED: fetching daily for index {symbol}")
                        daily_df = self.fetch_hk_daily_data(symbol)
                        
                        if not daily_df.empty and save_db:
                            # ğŸ”¥ æ–°æ¶æ„ï¼šä½¿ç”¨ç»Ÿä¸€ETLæµç¨‹
                            self.logger.info(f"Saving {symbol} to RawMarketData for ETL processing")
                            self.save_to_db(symbol, market, {'1d': daily_df})
                        
                        # æ„é€ è¿”å›å€¼ï¼ˆç”¨äºAPIå“åº”ï¼‰
                        if not daily_df.empty:
                            latest_row = daily_df.iloc[-1]
                            current_price = float(latest_row.get('æ”¶ç›˜', latest_row.get('close', 0)))
                            
                            # è®¡ç®—changeå’Œpct_changeï¼ˆç”¨äºè¿”å›å€¼ï¼‰
                            change = 0
                            pct_change = 0
                            if len(daily_df) >= 2:
                                prev_row = daily_df.iloc[-2]
                                prev_close = float(prev_row.get('æ”¶ç›˜', prev_row.get('close', 0)))
                                if prev_close > 0:
                                    change = current_price - prev_close
                                    pct_change = (change / prev_close) * 100
                            
                            latest_data = {
                                'symbol': symbol,
                                'market': market,
                                'price': current_price,
                                'close': current_price,
                                'open': float(latest_row.get('å¼€ç›˜', latest_row.get('open', 0))),
                                'high': float(latest_row.get('æœ€é«˜', latest_row.get('high', 0))),
                                'low': float(latest_row.get('æœ€ä½', latest_row.get('low', 0))),
                                'volume': int(latest_row.get('æˆäº¤é‡', latest_row.get('volume', 0))),
                                'date': str(latest_row.get('timestamp', '')),  # â† ä½¿ç”¨timestamp
                                'change': change,
                                'pct_change': pct_change
                            }
                        else:
                            latest_data = None
                    
                    # HKæŒ‡æ•°ï¼šå·²é€šè¿‡ETLå¤„ç†ï¼Œè·³è¿‡åç»­dfå¤„ç†
                    df = None
                    skip_direct_save = True  # æ ‡è®°ï¼šå·²é€šè¿‡ETLï¼Œè·³è¿‡ç›´æ¥ä¿å­˜é€»è¾‘
                    
                else:
                    # --- HKä¸ªè‚¡åˆ†æ”¯ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰---
                    self.logger.info(f"HK Stock: fetching minute data for {symbol}")
                    df = self.fetch_hk_min_data(symbol, period='1')
                
            elif market == "US":
                if is_open:
                    # å¼€å¸‚ï¼šåˆ†é’Ÿæ•°æ®
                    self.logger.info(f"US Market OPEN: fetching minute data for {symbol}")
                    if symbol.startswith('^'):
                        df = pd.DataFrame()  # Indices skip AkShare
                    else:
                        symbol_min = self.to_akshare_us_symbol(symbol, for_minute=True)
                        df = self.fetch_us_min_data(symbol_min)
                else:
                    # é—­å¸‚ï¼šä½¿ç”¨yfinanceæ—¥çº¿æ•°æ®
                    self.logger.info(f"US Market CLOSED: fetching daily data via yfinance for {symbol}")
                    try:
                        df = self._fetch_fallback_yfinance(symbol, market)
                        if df is not None and not df.empty:
                            # yfinanceè¿”å›çš„æ˜¯æ—¥çº¿æ•°æ®ï¼Œæ—¶é—´å¯èƒ½æ˜¯00:00ï¼Œè®¾ç½®ä¸º16:00 ET
                            if 'timestamp' in df.columns:
                                df['timestamp'] = pd.to_datetime(df['timestamp'])
                                # æ£€æŸ¥æ˜¯å¦ä¸º00:00ï¼Œå¦‚æœæ˜¯åˆ™æ”¹ä¸º16:00
                                df['timestamp'] = df['timestamp'].apply(
                                    lambda x: x.replace(hour=16, minute=0, second=0) if x.hour == 0 else x
                                )
                            self.logger.info(f"âœ… US daily data fetched via yfinance")
                    except Exception as e:
                        self.logger.error(f"US yfinance fallback failed: {e}")
                        df = pd.DataFrame()

            
            latest_data = None # Initialize to avoid UnboundLocalError

            if df is not None and not df.empty:
                # --- RULE 4: Write-Through ---
                # We save the latest data point as '1d' so it acts as the cached snapshot.
                # Use iloc[[-1]] to keep it as a DataFrame
                try:
                    last_row_df = df.iloc[[-1]].copy()
                    # Ensure Date is string or compatible for save_to_db logic
                    if save_db:
                        self.save_to_db(symbol, market, {'1d': last_row_df})
                        self.logger.info(f"Write-Through: Saved latest snapshot for {symbol}")
                    else:
                        self.logger.info(f"Write-Through: Skipped saving snapshot for {symbol} (save_db=False)")
                except Exception as w_err:
                    self.logger.error(f"Write-Through failed: {w_err}")
                
                # Get last row for return
                latest = df.iloc[-1]
                
                # Format Timestamp Explicitly
                time_val = latest.get('timestamp')  # â† ä¿®å¤ï¼šä½¿ç”¨timestamp
                dt_obj = None
                date_str = ""
                
                # OPTIMIZATION: If source already provided a formatted date, use it (e.g. from AkShare or previous step)
                if 'date' in latest and latest['date']:
                    date_str = str(latest['date'])
                    # Ensure seconds if missing
                    if len(date_str) == 16: # 2025-12-16 13:47
                         date_str += ":00"
                    elif len(date_str) == 10: # 2025-12-16
                         # If strictly date, we might want to check market status or leave as is?
                         # But for 1min data, it should have time.
                         pass
                    self.logger.info(f"Using pre-existing date field: {date_str}")
                else:
                    # 1. Parse into datetime object using time_val
                    if pd.api.types.is_datetime64_any_dtype(df['timestamp']) and hasattr(time_val, 'to_pydatetime'):
                         dt_obj = time_val.to_pydatetime()
                    else:
                         try:
                            dt_obj = pd.to_datetime(time_val).to_pydatetime()
                         except:
                            pass
                    
                    # 2. Timezone Conversion & Normalization (Crucial for US/CN/HK)
                    if dt_obj:
                        has_time_component = (dt_obj.hour != 0 or dt_obj.minute != 0)
                        
                        if market == "US":
                             # Heuristic: If time component exists (not 00:00)
                             if has_time_component:
                                 us_tz = pytz.timezone('US/Eastern')
                                 if dt_obj.tzinfo is None:
                                     dt_us = us_tz.localize(dt_obj)
                                 else:
                                     dt_us = dt_obj.astimezone(us_tz)
                                 date_str = dt_us.strftime('%Y-%m-%d %H:%M:%S')
                             else:
                                 # US Daily: Set to 16:00 ET
                                 dt_obj = dt_obj.replace(hour=16, minute=0, second=0)
                                 date_str = dt_obj.strftime('%Y-%m-%d %H:%M:%S')
                                 
                        elif market == "CN":
                            # CN Normalization: If 00:00:00, set to 15:00
                             if not has_time_component:
                                 dt_obj = dt_obj.replace(hour=15, minute=0, second=0)
                                 self.logger.info(f"CN Daily Normalization: 00:00 -> {dt_obj}")
                             date_str = dt_obj.strftime('%Y-%m-%d %H:%M:%S')
                             
                        elif market == "HK":
                             # HK Normalization: If 00:00:00, set to 16:00
                             if not has_time_component:
                                 dt_obj = dt_obj.replace(hour=16, minute=0, second=0)
                                 self.logger.info(f"HK Daily Normalization: 00:00 -> {dt_obj}")
                             date_str = dt_obj.strftime('%Y-%m-%d %H:%M:%S')
                             
                        else:
                             # Default
                             date_str = dt_obj.strftime('%Y-%m-%d %H:%M:%S')
                             
                        self.logger.info(f"Parsed DateStr: {date_str} (dt={dt_obj})")
                    else:
                        date_str = str(time_val)
                        self.logger.info(f"DEBUG: Failed to parse dt_obj. Raw: {time_val}")

                # Filter for the latest date in the dataframe
                time_col = 'timestamp'  # ç»Ÿä¸€ä½¿ç”¨timestamp
                latest_date_str = str(latest.get(time_col, '')).split(' ')[0]
                
                # Identify volume column
                vol_col = 'æˆäº¤é‡' if 'æˆäº¤é‡' in df.columns else 'volume'
                if vol_col not in df.columns: vol_col = None

                # Check if time column is datetime
                if time_col in df.columns and pd.api.types.is_datetime64_any_dtype(df[time_col]):
                     # Filter rows with same date as latest row
                    latest_date_val = latest[time_col].date()
                    day_df = df[df[time_col].dt.date == latest_date_val]
                    total_vol = day_df[vol_col].sum() if vol_col else 0
                else:
                    try: 
                        total_vol = df[vol_col].sum() if vol_col else 0
                    except:
                        total_vol = latest.get(vol_col, 0) if vol_col else 0

                latest_data = {
                    "symbol": symbol,
                    "market": market,
                    "date": date_str,
                    "volume": int(total_vol), # Cumulative Volume
                    "open": float(latest.get('å¼€ç›˜') or latest.get('open') or 0),
                    "high": float(latest.get('æœ€é«˜') or latest.get('high') or 0),
                    "low": float(latest.get('æœ€ä½') or latest.get('low') or 0),
                    "close": float(latest.get('æ”¶ç›˜') or latest.get('close') or 0),
                    "price": float(latest.get('æ”¶ç›˜') or latest.get('close') or 0) # Alias
                }
            
            # Merge with Yahoo Indicators (for Yield, PE, MarketCap)
            # This also serves as a Fallback if primary fetch failed (so latest_data might be None at start of this block)
            try:
                indicators = self.fetch_yahoo_indicators(symbol)
                if indicators:
                    # If primary fetch failed, try to construct latest_data from Yahoo
                    if latest_data is None:
                        # DEBUG
                        self.logger.info(f"DEBUG: latest_data is None, constructing from Yahoo for {symbol}")
                        # Yahoo has 'price', 'volume' (Daily), 'dividend_yield'
                        # We need 'date'
                        from datetime import datetime, timedelta
                        import pytz
                        
                        now = datetime.now(pytz.timezone('Asia/Shanghai'))
                        
                        if market == "US":
                            us_tz = pytz.timezone('US/Eastern')
                            us_now = now.astimezone(us_tz)
                            
                            # Logic: If Market is Closed (Weekend or outside 09:30-16:00), show Closing Time
                            if us_now.weekday() >= 5:
                                # Weekend -> Show last Friday
                                offset = us_now.weekday() - 4
                                last_close = us_now - timedelta(days=offset)
                                date_str = f"{last_close.strftime('%Y-%m-%d')} 16:00:00"
                            elif us_now.time() >= dtime(16, 0):
                                # Weekday after close -> Show Today 16:00
                                date_str = f"{us_now.strftime('%Y-%m-%d')} 16:00:00"
                            elif us_now.time() < dtime(9, 30):
                                # Weekday PRE-MARKET (before 09:30) -> Show Yesterday 16:00
                                last_close = us_now - timedelta(days=1)
                                # Handle Monday pre-market -> Show Friday
                                while last_close.weekday() >= 5:
                                    last_close = last_close - timedelta(days=1)
                                date_str = f"{last_close.strftime('%Y-%m-%d')} 16:00:00"
                            else:
                                # Market Open (09:30-16:00) -> Use current time
                                date_str = f"{us_now.strftime('%Y-%m-%d %H:%M:%S')}"
                        else:
                            date_str = now.strftime('%Y-%m-%d %H:%M:%S')
                        
                        latest_data = {
                            "symbol": symbol,
                            "market": market,
                            "date": date_str,
                            "volume": indicators.get('volume', 0),
                            "open": indicators.get('open', 0),
                            "high": indicators.get('dayHigh', indicators.get('high', 0)), # Yahoo info often uses dayHigh/dayLow
                            "low": indicators.get('dayLow', indicators.get('low', 0)),
                            "close": indicators.get('price', 0),
                            "price": indicators.get('price', 0)
                        }
                    
                    # Merge Indicators (PE, Div)
                    for k, v in indicators.items():
                         if k == 'volume': continue
                         # Don't overwrite existing valid data unless missing
                         if k not in latest_data or latest_data[k] is None or latest_data[k] == 0:
                            latest_data[k] = v
                    
                    self.logger.info(f"DEBUG: Post-Merge latest_data: {latest_data}")
                    
                    # FORCE Update Price for US Stocks from Yahoo (more realtime?)
                    if market == "US" and indicators.get('price'):
                         latest_data['price'] = indicators['price']
                         latest_data['close'] = indicators['price']
                         # Force update open if available to ensure correct change %
                         if indicators.get('open'): latest_data['open'] = indicators['open']
            
            except Exception as e:
                # self.logger.error(f"Yahoo Fallback Failed: {e}")
                pass

            # Fallback for Zero Price (Common in closed market for US/HK)
            if latest_data:
                # Check for data quality issues that require fallback
                # 1. Price is 0 (Critical missing)
                # 2. Change/PctChange is 0 (Likely closed market snapshot missing yesterday's reference)
                price_is_zero = latest_data.get('price', 0) == 0 and latest_data.get('close', 0) == 0
                change_is_zero = latest_data.get('change', 0) == 0 and latest_data.get('pct_change', 0) == 0
                
                if price_is_zero or change_is_zero:
                    reason = "Price is 0" if price_is_zero else "Change is 0"
                    self.logger.warning(f"Data incomplete ({reason}) for {symbol}. Attempting daily history fallback/repair.")
                    
                    try:
                         # Fetch 5 days of daily history to ensure we have 'Yesterday'
                         daily = None
                         if market == 'US':
                             daily = self.fetch_us_daily_data(self.to_akshare_us_symbol(symbol))
                         elif market == 'HK':
                             daily = self.fetch_hk_daily_data(symbol)
                         elif market == 'CN':
                             daily = self.fetch_cn_daily_data(symbol)
                         
                         
                         if daily is not None and not daily.empty:
                             # Ensure sorted by date!
                             if 'timestamp' in daily.columns:
                                 daily = daily.sort_values('timestamp')
                             
                             last_row = daily.iloc[-1]

                             # Map daily columns to latest_data format
                             # Robust Key Lookup for Close
                             valid_close = float(last_row.get('close') or last_row.get('Close') or last_row.get('æ”¶ç›˜') or 0)

                             if valid_close > 0:
                                 # If original price was 0, use this. 
                                 # If original price existed but Change was 0, we trust Realtime Price, but use History for Change Calc?
                                 # Better to use History for Price too if we are falling back, to ensure consistency with Change.
                                 latest_data['close'] = valid_close
                                 latest_data['price'] = valid_close
                                 
                                 open_val = last_row.get('open') or last_row.get('Open') or last_row.get('å¼€ç›˜')
                                 if open_val: latest_data['open'] = float(open_val)
                                     
                                 high_val = last_row.get('high') or last_row.get('High') or last_row.get('æœ€é«˜')
                                 if high_val: latest_data['high'] = float(high_val)
                                     
                                 low_val = last_row.get('low') or last_row.get('Low') or last_row.get('æœ€ä½')
                                 if low_val: latest_data['low'] = float(low_val)

                                 # Robust Volume Fetch
                                 vol = last_row.get('volume') or last_row.get('Volume') or last_row.get('æˆäº¤é‡') or 0
                                 latest_data['volume'] = int(vol)
                                 
                                 # Robust Turnover Fetch/Calc
                                 tvr = last_row.get('turnover') or last_row.get('Turnover') or last_row.get('æˆäº¤é¢')
                                 if tvr is None and latest_data.get('close') and latest_data.get('volume'):
                                     tvr = latest_data['close'] * latest_data['volume']
                                 if tvr: latest_data['turnover'] = float(tvr)

                                  
                                 # Use the historical date so user knows it's not live (ONLY if we don't have a better one)
                                 has_high_precision_time = latest_data.get('date') and len(str(latest_data['date'])) > 10
                                 if not has_high_precision_time:
                                     if 'timestamp' in last_row: latest_data['date'] = str(last_row['timestamp'])
                                     elif 'date' in last_row: latest_data['date'] = str(last_row['date'])
                                 
                                 # Attempt to extract indicators if present in history (rare)
                                 # 'pe', 'pb' usually not in candles, but let's try
                                 if 'pe' in last_row: latest_data['pe'] = float(last_row['pe'])
                                 

                    except Exception as fb_e:
                        self.logger.error(f"Daily fallback failed: {fb_e}")

                # If price_is_zero or change_is_zero, try to recalculate 'change' and 'pct_change'
                # This fixes the "+0.00%" issue for stocks like BABA (09988.hk)
                # This block should be after the daily fallback, as daily fallback might provide prev_close
                if latest_data:
                    # Check for zero data after fallback
                    price_is_zero = latest_data.get('price', 0) == 0 and latest_data.get('close', 0) == 0
                    change_is_zero = latest_data.get('change', 0) == 0 and latest_data.get('pct_change', 0) == 0

                    if price_is_zero or change_is_zero:
                        p_close = latest_data.get('prev_close', 0)
                        curr_price = latest_data.get('price', 0)
                        
                        if curr_price > 0 and p_close and p_close > 0:
                            recalc_change = curr_price - p_close
                            recalc_pct = (recalc_change / p_close) * 100
                            
                            if change_is_zero:
                                latest_data['change'] = recalc_change
                                latest_data['pct_change'] = recalc_pct
                                self.logger.info(f"Fixed 0% change for {symbol}: {recalc_pct:.2f}%")

                # If still zero price OR latest_data is None, try Fallback Min
                # Check safe access
                current_price = latest_data.get('price', 0) if latest_data else 0
                
                if current_price == 0:
                    self.logger.warning(f"Price still 0 for {symbol}. Attempting Yahoo minute fallback.")
                    try:
                        # Fetch 1 day of minute data from Yahoo
                        yf_symbol = self.to_yfinance_symbol(symbol, market)
                        import yfinance as yf
                        stock = yf.Ticker(yf_symbol)
                        hist = stock.history(period="1d", interval="1m")
                        
                        if not hist.empty:
                            last_minute_data = hist.iloc[-1]
                            # Initialize latest_data if None
                            if latest_data is None:
                                latest_data = {
                                    "symbol": symbol,
                                    "market": market,
                                    "date": last_minute_data.name.strftime('%Y-%m-%d %H:%M')
                                }

                            latest_data['price'] = float(last_minute_data['Close'])
                            latest_data['close'] = float(last_minute_data['Close'])
                            latest_data['open'] = float(last_minute_data['Open'])
                            latest_data['high'] = float(last_minute_data['High'])
                            latest_data['low'] = float(last_minute_data['Low'])
                            latest_data['volume'] = int(last_minute_data['Volume'])
                            latest_data['date'] = last_minute_data.name.strftime('%Y-%m-%d %H:%M')
                            self.logger.info(f"Yahoo minute fallback successful for {symbol}. Price: {latest_data['price']}")
                    except Exception as yf_min_e:
                        self.logger.error(f"Yahoo minute fallback failed for {symbol}: {yf_min_e}")


            # --- FINAL ENRICHMENT: Fetch Yahoo Indicators if still missing ---
            # This ensures PE, Dividend Yield, etc. are populated even if primary source lacks them.
            if latest_data:
                 # Check if we are missing key indicators
                 missing_indicators = False
                 for key in ['pe', 'dividend_yield', 'eps']:
                     if latest_data.get(key) is None:
                         missing_indicators = True
                         break
                 
                 if missing_indicators:
                     try:
                         # self.logger.info(f"Enriching {symbol} with Yahoo indicators...")
                         indicators = self.fetch_yahoo_indicators(symbol)
                         if indicators:
                             if not latest_data.get('pe') and indicators.get('pe'): 
                                 latest_data['pe'] = indicators.get('pe')
                             if not latest_data.get('dividend_yield') and indicators.get('dividend_yield'): 
                                 latest_data['dividend_yield'] = indicators.get('dividend_yield')
                             if not latest_data.get('eps') and indicators.get('eps'): 
                                 latest_data['eps'] = indicators.get('eps')
                             if not latest_data.get('market_cap') and indicators.get('market_cap'): 
                                 latest_data['market_cap'] = indicators.get('market_cap')
                             if not latest_data.get('pb') and indicators.get('pb'):
                                 latest_data['pb'] = indicators.get('pb')
                             if not latest_data.get('prev_close') and indicators.get('prev_close'):
                                 latest_data['prev_close'] = indicators.get('prev_close')

                     except Exception as ye:
                         self.logger.warning(f"Yahoo enrichment failed for {symbol}: {ye}")

            # --- RETRY CALCULATION: If Change is still 0, try calc using enriched prev_close ---
            if latest_data:
                price_is_zero = latest_data.get('price', 0) == 0 and latest_data.get('close', 0) == 0
                change_is_zero = latest_data.get('change', 0) == 0 and latest_data.get('pct_change', 0) == 0
                
                self.logger.info(f"DEBUG: Recalc Check - PriceZero:{price_is_zero}, ChangeZero:{change_is_zero}, PrevClose:{latest_data.get('prev_close')}, Price:{latest_data.get('price')}")

                if (price_is_zero or change_is_zero):
                    p_close = latest_data.get('prev_close', 0)
                    curr_price = latest_data.get('price', 0)
                    
                    if curr_price > 0 and p_close and p_close > 0:
                        recalc_change = curr_price - p_close
                        recalc_pct = (recalc_change / p_close) * 100
                        
                        if change_is_zero:
                            latest_data['change'] = recalc_change
                            latest_data['pct_change'] = recalc_pct
                            self.logger.info(f"Fixed 0% change for {symbol} (Post-Enrichment): {recalc_pct:.2f}%")

            # âœ… æ‰€æœ‰æ•°æ®å·²é€šè¿‡Line 890çš„save_to_db()èµ°ETLæµç¨‹
            # ä¸å†éœ€è¦ç›´æ¥ä¿å­˜åˆ°MarketDataDaily/MarketSnapshot

            # --- FINAL: Data Validation & Return ---
            if latest_data:
                # æ•°æ®éªŒè¯å’Œæ¸…ç†
                from data_validator import get_validator
                validator = get_validator()
                is_valid = validator.validate_and_log(symbol, latest_data, self.logger)
                
                if not is_valid:
                    self.logger.warning(f"Data quality issues for {symbol}, but returning anyway")
                
                latest_data = validator.sanitize_data(latest_data)
                return latest_data
            else:
                return None
        except Exception as e:
            self.logger.error(f"Error fetching latest data for {symbol}: {e}")
        return None

                    
    def fetch_hk_index_realtime(self, symbol: str) -> dict:
        """
        HKæŒ‡æ•°å®æ—¶æ•°æ®è·å–ï¼ˆç»Ÿä¸€æ¶æ„ï¼šåªè·å–æ•°æ®ï¼Œä¸åˆ¤æ–­çŠ¶æ€ï¼Œä¸ä¿å­˜æ•°æ®åº“ï¼‰
        
        æ··åˆç­–ç•¥ï¼š
        - ä¸»ç­–ç•¥ï¼šAkShare spot_sina (å®æ—¶å¿«ç…§)
        - è¾…åŠ©ï¼šyfinance 1åˆ†é’Ÿæ•°æ®
        
        Returns:
            dict with keys: symbol, market, price, close, open, high, low, 
                           change, pct_change, volume, date
            None if all sources fail
        """
        try:
            # === ä¸»ç­–ç•¥ï¼šAkShareå®æ—¶å¿«ç…§ ===
            self.logger.info(f"Fetching HK index realtime (AkShare spot): {symbol}")
            
            try:
                df = ak.stock_hk_index_spot_sina()
                matches = df[df['ä»£ç '].str.upper() == symbol.upper()]
                
                if not matches.empty:
                    row = matches.iloc[0]
                    
                    # è½¬æ¢ä¸ºç»Ÿä¸€dictæ ¼å¼
                    from datetime import datetime
                    import pytz
                    hk_tz = pytz.timezone('Asia/Hong_Kong')
                    now = datetime.now(hk_tz)
                    
                    current_price = float(row['æœ€æ–°ä»·'])
                    
                    # ğŸ”¥ ä¿®å¤ï¼šä¸ä¿¡ä»»APIçš„æ¶¨è·Œé¢/æ¶¨è·Œå¹…ï¼Œä»æ•°æ®åº“æŸ¥è¯¢å‰ä¸€æ—¥æ”¶ç›˜ä»·è®¡ç®—
                    change = 0
                    pct_change = 0
                    prev_close = None
                    
                    try:
                        from database import engine
                        from sqlmodel import Session, select
                        
                        with Session(engine) as session:
                            prev_record = session.exec(
                                select(MarketDataDaily).where(
                                    MarketDataDaily.symbol == symbol,
                                    MarketDataDaily.market == 'HK'
                                ).order_by(MarketDataDaily.date.desc()).limit(1)
                            ).first()
                            
                            if prev_record and prev_record.close > 0:
                                prev_close = prev_record.close
                                change = current_price - prev_close
                                pct_change = (change / prev_close) * 100
                                self.logger.info(f"âœ… HK Index {symbol}: calculated change from DB: {change:.2f} ({pct_change:.2f}%)")
                            else:
                                # Fallback: ä½¿ç”¨ä»Šå¼€ä½œä¸ºå‚è€ƒï¼ˆä¸å‡†ç¡®ä½†æ€»æ¯”0å¥½ï¼‰
                                open_price = float(row['ä»Šå¼€'])
                                if open_price > 0:
                                    change = current_price - open_price
                                    pct_change = (change / open_price) * 100
                                    self.logger.warning(f"HK Index {symbol}: using open as fallback: {change:.2f} ({pct_change:.2f}%)")
                    except Exception as calc_e:
                        self.logger.warning(f"Failed to calculate change for {symbol}: {calc_e}")
                    
                    result = {
                        'symbol': symbol,
                        'market': 'HK',
                        'price': current_price,
                        'close': current_price,
                        'open': float(row['ä»Šå¼€']),
                        'high': float(row['æœ€é«˜']),
                        'low': float(row['æœ€ä½']),
                        'change': change,
                        'pct_change': pct_change,
                        'prev_close': prev_close,
                        'volume': 0,  # æŒ‡æ•°æ— æˆäº¤é‡
                        'date': now.strftime('%Y-%m-%d %H:%M:%S'),
                        'timestamp': now.strftime('%Y-%m-%d %H:%M:%S')
                    }
                    
                    self.logger.info(f"âœ… AkShare spot: {symbol} = {result['price']}")
                    return result
                    
            except Exception as e:
                self.logger.warning(f"AkShare spot failed for {symbol}: {e}")
            
            # === Fallbackï¼šyfinanceåˆ†é’Ÿæ•°æ® ===
            self.logger.info(f"Falling back to yfinance minute for {symbol}")
            
            from symbols_config import get_yfinance_symbol
            import yfinance as yf
            
            yf_symbol = get_yfinance_symbol(symbol)
            ticker = yf.Ticker(yf_symbol)
            hist = ticker.history(period='1d', interval='1m')
            
            if not hist.empty:
                last_row = hist.iloc[-1]
                last_time = hist.index[-1]
                current_price = float(last_row['Close'])
                
                # ğŸ”§ ä¿®å¤ï¼šæŸ¥è¯¢æ•°æ®åº“è·å–å‰ä¸€æ—¥æ”¶ç›˜ä»·æ¥è®¡ç®—æ¶¨è·Œå¹…
                prev_close = None
                change = 0
                pct_change = 0
                
                try:
                    from database import engine
                    from sqlmodel import Session, select
                    
                    with Session(engine) as session:
                        # å°è¯•ä»Dailyè¡¨æŸ¥è¯¢å‰ä¸€æ—¥æ”¶ç›˜ä»·
                        prev_record = session.exec(
                            select(MarketDataDaily).where(
                                MarketDataDaily.symbol == symbol,
                                MarketDataDaily.market == 'HK'
                            ).order_by(MarketDataDaily.date.desc()).limit(1)
                        ).first()
                        
                        if prev_record and prev_record.close > 0:
                            prev_close = prev_record.close
                            change = current_price - prev_close
                            pct_change = (change / prev_close) * 100
                            self.logger.info(f"âœ… Calculated change for {symbol}: {change:.2f} ({pct_change:.2f}%)")
                        else:
                            # Fallback: ä½¿ç”¨yfinanceçš„openä½œä¸ºå‚è€ƒ
                            if float(last_row['Open']) > 0:
                                prev_close = float(last_row['Open'])
                                change = current_price - prev_close
                                pct_change = (change / prev_close) * 100
                                self.logger.warning(f"Using open as prev_close for {symbol}: {change:.2f} ({pct_change:.2f}%)")
                except Exception as calc_e:
                    self.logger.warning(f"Failed to calculate change for {symbol}: {calc_e}")
                
                result = {
                    'symbol': symbol,
                    'market': 'HK',
                    'price': current_price,
                    'close': current_price,
                    'open': float(last_row['Open']),
                    'high': float(last_row['High']),
                    'low': float(last_row['Low']),
                    'volume': int(last_row['Volume']),
                    'date': last_time.strftime('%Y-%m-%d %H:%M:%S'),
                    'timestamp': last_time.strftime('%Y-%m-%d %H:%M:%S'),
                    'prev_close': prev_close,
                    'change': change,
                    'pct_change': pct_change
                }
                
                self.logger.info(f"âœ… yfinance minute fallback: {symbol} = {result['price']}")
                return result
            
            self.logger.error(f"Both AkShare and yfinance failed for {symbol}")
            return None
            
        except Exception as e:
            self.logger.error(f"Error in fetch_hk_index_realtime: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return None

    def fetch_from_tencent(self, symbol: str) -> dict:
        """
        Fetch real-time snapshot from Tencent (Qt)
        Symbol should be prefixed, e.g. 'hkHSTECH', 'hkHSI', 'sh600519'
        """
        try:
            import requests
            url = f"http://qt.gtimg.cn/q={symbol}"
            # Use random UA to be safe
            headers = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            }
            resp = requests.get(url, headers=headers, timeout=2)
            if resp.status_code != 200:
                return None
            
            content = resp.text.strip()
            # Format: v_hkHSTECH="100~æ’ç”Ÿç§‘æŠ€æŒ‡æ•°~HSTECH~5498.420~5638.050~5562.670~..."
            if '="' not in content:
                return None
                
            data_str = content.split('="')[1].strip('";')
            parts = data_str.split('~')
            
            if len(parts) < 30:
                return None
                
            # Parse (Standard GTimg format)
            # 1: Name 2: Code 3: Price 4: PrevClose 5: Open
            # 30: Time (YYYY/MM/DD HH:MM:SS) 31: Change 32: PctChange
            
            price = float(parts[3])
            prev_close = float(parts[4])
            open_p = float(parts[5])
            time_str = parts[30]
            # vol_str = parts[6] 
            # For HK Indices, parts[6] seems to be Turnover (money) or Volume (shares)?
            # Sina HSTECH: 56964428 (~56M)
            # Tencent HSTECH: 5696442.8498 (~5.6M) -> Maybe Lots? Or 1/100?
            # Usually users just want a relative magnitude.
            # Let's take parts[6] as Volume.
            vol_raw = float(parts[6]) if parts[6] else 0
            change = float(parts[31])
            pct_change = float(parts[32])
            
            return {
                "symbol": symbol, 
                "price": price,
                "close": price,
                "prev_close": prev_close,
                "open": open_p,
                "high": 0, 
                "low": 0,
                "change": change,
                "pct_change": pct_change,
                "volume": int(vol_raw), 
                "date": time_str,
                "market": "HK" if "hk" in symbol else "CN"
            }
            
        except Exception as e:
            self.logger.error(f"Tencent fetch failed for {symbol}: {e}")
            return None

    def fetch_cn_daily_data(self, symbol: str) -> pd.DataFrame:
        """
        CNæ—¥çº¿æ•°æ®ï¼šyfinanceä¼˜å…ˆï¼ŒAkShareå¤‡ç”¨
        """
        try:
            # === ä¼˜å…ˆä½¿ç”¨ yfinance ===
            self.logger.info(f"Fetching CN daily data (yfinance primary): {symbol}")
            df = self._fetch_fallback_yfinance(symbol, "CN")
            
            if df is not None and not df.empty:
                self.logger.info(f"âœ… yfinance CN daily: {len(df)} records for {symbol}")
                return df
            
            # === å¤‡ç”¨ï¼šAkShare ===
            self.logger.warning(f"yfinance empty for CN {symbol}, trying AkShare...")
            code = symbol.replace('.sh', '').replace('.sz', '').replace('.SH', '').replace('.SZ', '').zfill(6)
            self.logger.info(f"Falling back to AkShare: {symbol} â†’ {code}")
            
            df = ak.stock_zh_a_hist(symbol=code, period="daily", adjust="qfq")
            if df is not None and not df.empty and 'æ—¥æœŸ' in df.columns:
                df = self.standardize_akshare_fields(df)
                self.logger.info(f"âœ… AkShare CN daily (fallback): {len(df)} records for {symbol}")
                return df
            
            return pd.DataFrame()
            
        except Exception as e:
            self.logger.error(f"Error fetching CN daily data for {symbol}: {str(e)}")
            return pd.DataFrame()


    def fetch_hk_daily_data(self, symbol: str) -> pd.DataFrame:
        """
        HKæ—¥çº¿æ•°æ®ï¼šæŒ‡æ•°ç”¨yfinanceï¼ˆæ›´ç¨³å®šï¼‰ï¼Œä¸ªè‚¡ç”¨ä¸œæ–¹è´¢å¯Œ
        
        æ··åˆç­–ç•¥ï¼š
        - HKæŒ‡æ•°ï¼šä¸»ç”¨yfinanceï¼Œå¤‡ç”¨AkShareï¼ˆå› AkShare APIä¸ç¨³å®šï¼‰
        - HKä¸ªè‚¡ï¼šä¸»ç”¨AkShareä¸œæ–¹è´¢å¯Œï¼Œå¤‡ç”¨yfinance
        """
        try:
            from symbols_config import is_index, get_akshare_symbol
            
            if is_index(symbol):
                # === HKæŒ‡æ•°ï¼šä¼˜å…ˆyfinanceï¼ˆæ›´ç¨³å®šï¼‰ ===
                self.logger.info(f"Fetching HK index daily (yfinance primary): {symbol}")
                
                try:
                    df = self._fetch_fallback_yfinance(symbol, "HK")
                    if df is not None and not df.empty:
                        self.logger.info(f"âœ… yfinance HK index daily: {len(df)} records for {symbol}")
                        return df
                except Exception as e:
                    self.logger.warning(f"yfinance failed for HK index {symbol}: {e}")
                
                # Fallback: AkShare (ä½†å·²çŸ¥ä¸ç¨³å®š)
                akshare_code = get_akshare_symbol(symbol)
                self.logger.info(f"Falling back to AkShare: {symbol} â†’ {akshare_code}")
                
                try:
                    df = ak.stock_hk_index_daily_sina(symbol=akshare_code)
                    if df is not None and not df.empty:
                        df = self.standardize_akshare_fields(df)
                        
                        if 'prev_close' not in df.columns or df['prev_close'].isna().all():
                            df['prev_close'] = df['close'].shift(1)
                            self.logger.info(f"âœ… è®¡ç®—prev_close for {symbol} using shift()")
                        
                        self.logger.info(f"âœ… AkShare HK index daily (fallback): {len(df)} records for {symbol}")
                        return df
                except Exception as e:
                    self.logger.error(f"AkShare also failed for {symbol} (code={akshare_code}): {e}")
                    return pd.DataFrame()  # ä¸¤ä¸ªéƒ½å¤±è´¥ï¼Œè¿”å›ç©º
            
            else:
                # === HKä¸ªè‚¡ï¼šyfinanceä¼˜å…ˆï¼ŒAkShareå¤‡ç”¨ ===
                self.logger.info(f"Fetching HK stock daily (yfinance primary): {symbol}")
                
                # ä¼˜å…ˆä½¿ç”¨ yfinance
                df = self._fetch_fallback_yfinance(symbol, "HK")
                if df is not None and not df.empty:
                    self.logger.info(f"âœ… yfinance HK stock daily: {len(df)} records for {symbol}")
                    return df
                
                # å¤‡ç”¨ï¼šAkShareä¸œæ–¹è´¢å¯ŒAPI
                self.logger.warning(f"yfinance empty for HK stock {symbol}, trying AkShare...")
                code = symbol.replace('.hk', '').replace('.HK', '').zfill(5)
                self.logger.info(f"Falling back to AkShare: {symbol} â†’ {code}")
                
                df = ak.stock_hk_hist(symbol=code, period="daily")
                
                if df is not None and not df.empty and 'æ—¥æœŸ' in df.columns:
                    df = self.standardize_akshare_fields(df)
                    
                    # âœ… è®¡ç®—prev_closeï¼ˆå¦‚æœæ•°æ®æºæ²¡æœ‰æä¾›ï¼‰
                    if 'prev_close' not in df.columns or df['prev_close'].isna().all():
                        df['prev_close'] = df['close'].shift(1)
                        self.logger.info(f"âœ… è®¡ç®—prev_close for {symbol} using shift()")
                    
                    self.logger.info(f"âœ… AkShare HK stock daily (fallback): {len(df)} records for {symbol}")
                    return df
                
                return pd.DataFrame()
                
        except Exception as e:
            self.logger.error(f"Error in fetch_hk_daily_data: {e}")
            return self._fetch_fallback_yfinance(symbol, "HK")

    def _get_latest_daily_date(self, symbol: str, market: str):
        """
        æŸ¥è¯¢æ•°æ®åº“ä¸­symbolçš„æœ€æ–°æ—¥æœŸ
        ç”¨äºæ™ºèƒ½é€‰æ‹©yfinanceçš„periodå‚æ•°
        
        Returns:
            datetime or None: æœ€æ–°æ—¥æœŸï¼Œå¦‚æœæ²¡æœ‰æ•°æ®åˆ™è¿”å›None
        """
        try:
            from database import engine
            from models import MarketDataDaily
            from sqlmodel import Session, select
            from datetime import datetime
            
            with Session(engine) as session:
                stmt = select(MarketDataDaily).where(
                    MarketDataDaily.symbol == symbol,
                    MarketDataDaily.market == market
                ).order_by(MarketDataDaily.timestamp.desc()).limit(1)
                
                latest_record = session.exec(stmt).first()
                
                if latest_record and latest_record.timestamp:
                    # timestampå­—æ®µæ˜¯å­—ç¬¦ä¸²æ ¼å¼ "YYYY-MM-DD HH:MM:SS"
                    return datetime.strptime(latest_record.timestamp[:10], '%Y-%m-%d')
                
                return None
        except Exception as e:
            self.logger.warning(f"Failed to get latest date for {symbol}: {e}")
            return None

    def to_akshare_us_symbol(self, symbol, for_minute=False):
        # symbol å¯èƒ½æ˜¯ 105.msftã€106.tsmã€MSFTã€TSM
        if for_minute:
            # ä¿ç•™å‰ç¼€ï¼Œè½¬å°å†™
            if symbol.startswith("105.") or symbol.startswith("106."):
                return symbol.lower()
            if symbol.upper() == "TSM":
                return "106.tsm"
            # Default fallback assumption for US mapping if prefix missing
            return "105." + symbol.lower() 
        else:
            if symbol.startswith("105.") or symbol.startswith("106."):
                return symbol.split(".")[1].upper()
            return symbol.upper()

    def _fetch_fallback_yfinance(self, symbol: str, market: str) -> pd.DataFrame:
        import yfinance as yf
        try:
            # Use symbols_config for index symbol mapping (^NDX -> ^IXIC, ^SPX -> ^GSPC)
            from symbols_config import get_yfinance_symbol
            yf_symbol = get_yfinance_symbol(symbol)  # Will map if in config, otherwise returns original
            
            # Additional market-specific mappings for stocks (not indices)
            if yf_symbol == symbol:  # Not already mapped by config
                if market == "CN":
                    if symbol.endswith('.sh'):
                        yf_symbol = symbol.replace('.sh', '.SS')
                    elif symbol.endswith('.sz'):
                        yf_symbol = symbol.replace('.sz', '.SZ')
                elif market == "HK":
                    # HK stock symbols
                    if symbol.replace('.hk', '') == '800000':
                        yf_symbol = "^HSI"
                    elif symbol.replace('.hk', '') == '800700':
                        yf_symbol = "HSTECH.HK"
                    else:
                        code = symbol.replace('.hk', '')
                        if code.isdigit():
                            yf_symbol = f"{int(code):04d}.HK"
                        else:
                            yf_symbol = f"{code}.HK"
                elif market == "US":
                    # US stock symbols: strip suffix (.OQ, .N, etc)
                    if '.' in symbol and not symbol.startswith('^'):
                         yf_symbol = symbol.split('.')[0]


            # âš ï¸ DEBUG: è¿›å…¥fallback yfinance
            self.logger.info(f"[DEBUG] _fetch_fallback_yfinance: symbol={symbol}, market={market}, yf_symbol={yf_symbol}")
            self.logger.info(f"Fallback: fetching {yf_symbol} via yfinance...")
            stock = yf.Ticker(yf_symbol)
            
            # âœ… æ™ºèƒ½periodé€‰æ‹©ï¼šæ ¹æ®æ•°æ®ç¼ºå£å†³å®šè·å–èŒƒå›´
            self.logger.info(f"[DEBUG] Calling _get_latest_daily_date for {symbol}")
            latest_date = self._get_latest_daily_date(symbol, market)
            self.logger.info(f"[DEBUG] latest_date result: {latest_date}")
            
            if latest_date:
                from datetime import datetime
                gap_days = (datetime.now() - latest_date).days
                
                # æ ¹æ®ç¼ºå£å¤§å°é€‰æ‹©period
                if gap_days <= 5:
                    period = "5d"
                    self.logger.info(f"Gap {gap_days} days â†’ using period=5d")
                elif gap_days <= 30:
                    period = "1mo"
                    self.logger.info(f"Gap {gap_days} days â†’ using period=1mo")
                elif gap_days <= 90:
                    period = "3mo"
                    self.logger.info(f"Gap {gap_days} days â†’ using period=3mo")
                else:
                    period = "1y"
                    self.logger.info(f"Gap {gap_days} days â†’ using period=1y (large gap)")
            else:
                # æ–°symbolæˆ–æ— å†å²æ•°æ®ï¼šé»˜è®¤1ä¸ªæœˆ
                period = "1mo"
                self.logger.info(f"No existing data for {symbol} â†’ using period=1mo")
            
            # âš ï¸ HOTFIX: å¼ºåˆ¶ä½¿ç”¨5dç»•è¿‡æ™ºèƒ½é€‰æ‹©é—®é¢˜
            # æ™ºèƒ½é€‰æ‹©é€»è¾‘åœ¨asyncç¯å¢ƒä¸‹æœªèƒ½ç”Ÿæ•ˆï¼Œæš‚æ—¶ä½¿ç”¨å›ºå®š5dç¡®ä¿å¢é‡æ›´æ–°
            period = "5d"
            self.logger.info(f"[HOTFIX] Forcing period=5d for incremental update")
            
            hist = stock.history(period=period)
            
            if hist.empty:
                self.logger.warning(f"yfinance fallback also empty for {yf_symbol}")
                return pd.DataFrame()
            
            # Reset index to get Date
            hist = hist.reset_index()
            
            # For US market during trading hours: filter out today's data
            # yfinance returns today's real-time price with incorrect timestamp (00:00)
            if market == "US":
                from datetime import datetime, time as dtime
                import pytz
                us_tz = pytz.timezone('US/Eastern')
                us_now = datetime.now(us_tz)
                
                # Check if market is open (9:30-16:00 ET, weekdays)
                is_open = (us_now.weekday() < 5 and 
                          dtime(9, 30) <= us_now.time() < dtime(16, 0))
                
                if is_open:
                    # Filter out today's data - it's real-time price with wrong timestamp
                    today_str = us_now.strftime('%Y-%m-%d')
                    initial_len = len(hist)
                    hist = hist[~hist['Date'].dt.strftime('%Y-%m-%d').eq(today_str)]
                    filtered = initial_len - len(hist)
                    if filtered > 0:
                        self.logger.info(f"US Market OPEN: filtered out {filtered} today's data (real-time price with incorrect timestamp)")
            
            # Rename columns to match what save_to_db expects (English keys also work: open, close, etc.)
            # But let's map Date -> æ—¶é—´ just in case
            hist = hist.rename(columns={'Date': 'timestamp', 'Volume': 'volume', 'Open': 'open', 'High': 'high', 'Low': 'low', 'Close': 'close'})
            hist['timestamp'] = pd.to_datetime(hist['timestamp'])
            
            # Ensure naive timezone and set time to 16:00 (market close)
            if pd.api.types.is_datetime64_any_dtype(hist['timestamp']):
                hist['timestamp'] = hist['timestamp'].dt.tz_localize(None)
                # yfinanceè¿”å›çš„æ—¥çº¿æ—¶é—´æ˜¯00:00ï¼Œåº”è¯¥æ”¹ä¸º16:00ï¼ˆæ”¶ç›˜æ—¶é—´ï¼‰
                hist['timestamp'] = hist['timestamp'].apply(
                    lambda x: x.replace(hour=16, minute=0, second=0) if x.hour == 0 else x
                )
                
            # Add turnover approx if missing
            if 'turnover' not in hist.columns:
                 # Estimate turnover = close * volume
                hist['turnover'] = hist['close'] * hist['volume']
            
            # Add date column in standardized format for US market
            hist['date'] = hist['timestamp'].apply(lambda x: x.strftime('%Y-%m-%d 16:00:00'))
            
            self.logger.info(f"Fallback success for {symbol}. Got {len(hist)} rows.")
            return hist
            
        except Exception as e:
            self.logger.error(f"Fallback failed for {symbol}: {e}")
            return pd.DataFrame()

    def _fetch_fallback_yfinance_min(self, symbol: str, market: str) -> pd.DataFrame:
        """
        Fallback: Use yfinance to fetch minute data (1d, 1m).
        """
        import yfinance as yf
        try:
            # 1. Adapt Symbol for Yahoo
            yf_symbol = symbol
            if market == 'HK':
                # Existing HK logic (00700 -> 0700.HK)
                code = symbol.replace('.HK', '').replace('.hk', '')
                try:
                    code_int = int(code)
                    yf_symbol = f"{code_int:04d}.HK"
                except:
                    yf_symbol = symbol
            elif market == 'CN':
                 # Existing CN logic
                 yf_symbol = symbol.replace('.sh', '.SS').replace('.SH', '.SS') \
                                   .replace('.sz', '.SZ').replace('.SZ', '.SZ')
            elif market == 'US':
                # NEW: Remove "105." prefix for US stocks
                if '.' in symbol and symbol.split('.')[0].isdigit():
                    yf_symbol = symbol.split('.')[-1]
            
            self.logger.info(f"Fallback (Min): fetching {yf_symbol} ...")
            ticker = yf.Ticker(yf_symbol)
            # Yahoo minute data limited to 7 days usually. 
            # period='1d', interval='1m' is standard for basic realtime.
            df = ticker.history(period="1d", interval="1m")
            
            if df.empty:
                self.logger.warning(f"Fallback (Min): {yf_symbol} returned empty DataFrame")
                return pd.DataFrame()
                
            # Formatting
            df = df.reset_index()
            
            # Handle column names - yfinance uses 'Datetime' for minute data
            if 'Datetime' in df.columns:
                df = df.rename(columns={'Datetime': 'timestamp'})
            elif 'Date' in df.columns:
                df = df.rename(columns={'Date': 'timestamp'})
            
            # Rename price columns - ä½¿ç”¨è‹±æ–‡å­—æ®µåä»¥åŒ¹é…ETL
            df = df.rename(columns={
                'Open': 'open', 
                'High': 'high', 
                'Low': 'low', 
                'Close': 'close', 
                'Volume': 'volume'
            })
            
            # Add turnover if missing
            if 'turnover' not in df.columns and 'close' in df.columns:
                df['turnover'] = df['close'] * df['volume']
            
            # Ensure TZ naive - properly handle timezone-aware datetime
            if 'timestamp' in df.columns and pd.api.types.is_datetime64_any_dtype(df['timestamp']):
                # Check if timezone-aware
                if df['timestamp'].dt.tz is not None:
                    # Remove timezone by converting to naive datetime
                    df['timestamp'] = df['timestamp'].dt.tz_localize(None)
                
            self.logger.info(f"Fallback (Min): {yf_symbol} success, {len(df)} records")
            return df
        except Exception as e:

            self.logger.error(f"Fallback min error for {symbol}: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return pd.DataFrame()

    def fetch_us_daily_data(self, symbol: str) -> pd.DataFrame:
        """
        USæ—¥çº¿æ•°æ®ï¼šyfinanceä¼˜å…ˆï¼ŒAkShareå¤‡ç”¨
        """
        try:
            # æ ‡å‡†åŒ–USè‚¡ç¥¨ä»£ç ï¼šç§»é™¤äº¤æ˜“æ‰€åç¼€ (.OQ, .O, .Nç­‰)
            clean_symbol = symbol.split('.')[0] if '.' in symbol else symbol
            
            # === ä¼˜å…ˆä½¿ç”¨ yfinanceï¼ˆæ‰€æœ‰USè‚¡ç¥¨å’ŒæŒ‡æ•°ï¼‰ ===
            self.logger.info(f"Fetching US daily data (yfinance primary): {symbol}")
            df = self._fetch_fallback_yfinance(symbol, "US")
            
            if df is not None and not df.empty:
                self.logger.info(f"âœ… yfinance US daily: {len(df)} records for {symbol}")
                return df
            
            # === å¤‡ç”¨ï¼šAkShareï¼ˆä»…ç”¨äºä¸ªè‚¡ï¼Œä¸ç”¨äºæŒ‡æ•°ï¼‰ ===
            if clean_symbol.startswith("^"):
                # æŒ‡æ•°åªç”¨yfinanceï¼Œä¸ç”¨AkShare
                self.logger.warning(f"yfinance failed for US index {symbol}, no AkShare fallback for indices")
                return pd.DataFrame()
            
            self.logger.warning(f"yfinance empty for US {symbol}, trying AkShare...")
            self.logger.info(f"Falling back to AkShare: {symbol} â†’ {clean_symbol}")
            
            df = ak.stock_us_daily(symbol=clean_symbol)
            
            if df is not None and not df.empty and 'æ—¥æœŸ' in df.columns:
                df = self.standardize_akshare_fields(df)
                # åªä¿ç•™æœ€è¿‘30å¤©
                last_date = df['timestamp'].dt.date.max()
                first_date = last_date - pd.Timedelta(days=29)
                df = df[(df['timestamp'].dt.date >= first_date) & (df['timestamp'].dt.date <= last_date)]
                
                # âœ… è®¡ç®—prev_closeï¼ˆå¦‚æœæ•°æ®æºæ²¡æœ‰æä¾›ï¼‰
                if 'prev_close' not in df.columns or df['prev_close'].isna().all():
                    df['prev_close'] = df['close'].shift(1)
                    self.logger.info(f"âœ… è®¡ç®—prev_close for {symbol} using shift()")
                
                self.logger.info(f"âœ… AkShare US daily (fallback): {len(df)} records for {symbol}")
                return df
            
            return pd.DataFrame()
            
        except Exception as e:
            self.logger.error(f"Error fetching US daily data for {symbol}: {str(e)}")
            return pd.DataFrame()

    
    def save_to_db(self, symbol: str, market: str, period_data: dict) -> None:
        """
        NEW ETL PIPELINE:
        Fetch -> Raw Table -> ETL Service -> Prod Table
        """
        try:
            # âš ï¸ DEBUG: æ‰“å°period_dataé•¿åº¦
            for period, df in period_data.items():
                if df is not None and not df.empty:
                    self.logger.info(f"[DEBUG save_to_db] {symbol} {period}: {len(df)} records")
            
             # Normalize Symbol for DB
            db_symbol = normalize_symbol_db(symbol, market)
            
            from database import get_session
            from models import RawMarketData
            from etl_service import ETLService
            from field_normalizer import FieldNormalizer  # å¯¼å…¥å­—æ®µæ ‡å‡†åŒ–å™¨
            
            gen = get_session()
            session = next(gen, None)
            
            if not session:
                self.logger.error("Could not get DB session")
                return

            try:
                # Iterate periods (1d, 1m, etc)
                for period, df in period_data.items():
                    if df is None or df.empty:
                        continue
                    
                    # âœ… P0+P2: åº”ç”¨å­—æ®µæ ‡å‡†åŒ–
                    self.logger.info(f"Normalizing fields for {symbol} ({period})...")
                    df, norm_report = FieldNormalizer.normalize_dataframe(
                        df, 
                        source=None,  # è‡ªåŠ¨æ£€æµ‹
                        data_type='minute' if 'm' in period else 'daily',
                        market=market
                    )
                    
                    # è®°å½•æ ‡å‡†åŒ–ç»“æœ
                    if norm_report.get('warnings'):
                        self.logger.warning(f"Field normalization warnings for {symbol}: {norm_report['warnings']}")
                    
                    # Convert DF to JSON-serializable list of dicts
                    # Timestamps need string conversion
                    df_json = df.copy()
                    if 'timestamp' in df_json.columns:
                        df_json['date'] = df_json['timestamp'].astype(str)
                    elif 'timestamp' in df_json.columns:
                        df_json['date'] = df_json['timestamp'].astype(str)
                    
                    # Serialize
                    payload = df_json.to_json(orient='records')
                    
                    # 1. RAW INGESTION
                    raw = RawMarketData(
                        source="fetched",
                        symbol=db_symbol,
                        market=market,
                        period=period,
                        payload=payload,
                        processed=False
                    )
                    session.add(raw)
                    session.commit()
                    session.refresh(raw)
                    
                    # âœ… 2. TRIGGER ETL (Async via Queue)
                    # æ—§æ¨¡å¼: åŒæ­¥ETL,é˜»å¡ç”¨æˆ·å“åº”(150ç§’)
                    # ETLService.process_raw_data(raw.id)
                    
                    # âœ… æ–°æ¨¡å¼: å¼‚æ­¥ETL,ç«‹å³è¿”å›(5ç§’)
                    from etl_queue import etl_queue
                    etl_queue.enqueue(raw.id)
                    self.logger.info(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°Rawè¡¨ (raw_id={raw.id}), ETLä»»åŠ¡å·²å…¥é˜Ÿ")
            
            except Exception as e:
                self.logger.error(f"Ingest/ETL Loop Error: {e}")
            finally:
                session.close()

        except Exception as e:
            self.logger.error(f"Critical error in save_to_db: {e}")


    def save_fund_flow(self, symbol: str):
        # åªé‡‡é›†Aè‚¡èµ„é‡‘æµå‘
        if symbol.endswith('.sh') or symbol.endswith('.sz') or symbol.endswith('.bj'):
            stock = symbol[:6]
            market = "CN"
            try:
                # Proceeded dir logic
                market_dir = os.path.join(self.output_dir, "proceeded", market)
                os.makedirs(market_dir, exist_ok=True)
                
                fund_flow_df = ak.stock_individual_fund_flow(stock=stock, market=symbol[-2:])
                if fund_flow_df is not None and not fund_flow_df.empty:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"{symbol}_{market}_fund_flow_{timestamp}_V4.xlsx"
                    filepath = os.path.join(market_dir, filename)
                    fund_flow_df.to_excel(filepath, index=False)
                    self.logger.info(f"èµ„é‡‘æµå‘å·²ä¿å­˜åˆ° {filepath}")
            except Exception as e:
                self.logger.error(f"èµ„é‡‘æµå‘è·å–å¤±è´¥: {symbol}, åŸå› : {e}")


    def _get_market(self, symbol):
        symbol = symbol.upper()
        if symbol.startswith("105.") or symbol.startswith("106."):
            return "US"
        elif symbol.startswith("^"):
            return "US"
        elif symbol.endswith(".HK"):
            return "HK"
        elif symbol.endswith(".SH") or symbol.endswith(".SZ"):
            return "CN"
        # US Suffixes from EastMoney search
        elif any(symbol.endswith(s) for s in [".OQ", ".N", ".AM", ".O", ".K"]):
            return "US"
        # Plain US symbols (no dot) - naive check?
        # risky if overlaps with others, but usually 3-4 chars is US if not CN/HK.
        # Let's rely on suffixes for now as SearchBar seems to provide them.
        else:
            return "Other"

    def get_stock_name(self, symbol: str) -> str:
        market = self._get_market(symbol)
        name = symbol
        
        # Helper to fetch from Tencent (qt.gtimg.cn)
        def fetch_from_tencent(code_with_prefix):
            try:
                url = f"http://qt.gtimg.cn/q={code_with_prefix}"
                headers = {"User-Agent": "Mozilla/5.0"}
                resp = requests.get(url, headers=headers, timeout=5)
                if resp.status_code == 200:
                    # format: v_hk00005="100~æ±‡ä¸°æ§è‚¡~..."
                    content = resp.text
                    if '="' in content:
                        data_str = content.split('="')[1].strip('";')
                        parts = data_str.split('~')
                        if len(parts) > 2:
                            return parts[1] # Name is usually at index 1
            except Exception as e:
                self.logger.error(f"Tencent fetch error for {code_with_prefix}: {e}")
            return None

        try:
            if market == "CN":
                code = symbol.replace('.sh', '').replace('.sz', '').zfill(6)
                # Try Tencent first for speed? Or keep AkShare. 
                # AkShare is reliable for CN. Keep AkShare.
                df = ak.stock_individual_info_em(symbol=code)
                if df is not None and not df.empty:
                    row = df[df['item'] == 'è‚¡ç¥¨ç®€ç§°']
                    if not row.empty:
                        name = row.iloc[0]['value']
                        
            elif market == "HK":
                # Tencent format: hk00005
                code = symbol.replace('.hk', '')
                fetched = fetch_from_tencent(f"hk{code}")
                if fetched: name = fetched
                
            elif market == "US":
                # Tencent format: usAAPL
                # Our symbol: 105.aapl or just AAPL?
                # to_akshare_us_symbol format: "105.aapl"
                # Extract clean symbol
                clean_symbol = symbol.split(".")[-1].upper() # aapl -> AAPL
                fetched = fetch_from_tencent(f"us{clean_symbol}")
                if fetched: name = fetched
                
        except Exception as e:
            self.logger.error(f"Error getting name for {symbol}: {e}")
        return name

    def _is_daily_data_current(self, symbol: str, market: str) -> bool:
        """
        Check if we already have daily data for the 'current' trading day.
        """
        try:
            from database import engine
            from models import MarketDataDaily
            from sqlmodel import Session, select, func
            
            # Determine 'Expected' Date
            # Simple logic: 
            # CN/HK: Today's date (Asia/Shanghai)
            # US: Today's date (US/Eastern)
            # If market is Open, maybe we DON'T skip? 
            # User said "If already exists, don't duplicate". This usually refers to historical backfill.
            # But if today is trading, do we want to re-fetch to get close price updates?
            # User phrase: "marketdata_full, same date only save one. If exists, don't fetch."
            # This implies if we have a record for TODAY, we assume it's done?
            # Or maybe just for historical?
            # Let's be safe: If we have a record for TODAY, and market is CLOSED, definitely skip.
            # If market is OPEN, we might want to update? 
            # But let's follow instruction "If exists... don't fetch".
            
            now = datetime.now(pytz.timezone('Asia/Shanghai'))
            expected_date = now.date()
            
            if market == 'US':
                expected_date = now.astimezone(pytz.timezone('US/Eastern')).date()
            
            with Session(engine) as session:
                # Check for 1d record with Date starts with YYYY-MM-DD
                # Since date is String, use startswith
                date_prefix = expected_date.strftime("%Y-%m-%d")
                
                # Check directly
                statement = select(MarketDataDaily).where(
                    MarketDataDaily.symbol == normalize_symbol_db(symbol, market),
                    MarketDataDaily.market == market,
                    MarketDataDaily.date.startswith(date_prefix)
                )
                existing = session.exec(statement).first()
                
                if existing:
                    return True
                    
        except Exception as e:
            self.logger.error(f"Check existing failed for {symbol}: {e}")
            
        return False

    # NOTE: Modified fetch_all_stocks to accept an optional 'markets' filter and 'specific_symbols'
    def fetch_all_stocks(self, periods, target_markets=None, specific_symbols: list = None):
        import time, random
        target_list = specific_symbols if specific_symbols is not None else self.symbols
        self.logger.info(f"Starting to fetch data for {len(target_list)} stocks, periods: {periods}")
        
        consecutive_fails = 0
        
        for i, symbol in enumerate(target_list):
            # Safety: Random delay between requests
            if i > 0:
                time.sleep(random.uniform(1.0, 3.0))
            
            # Circuit Breaker
            if consecutive_fails >= 5:
                self.logger.warning("Circuit Breaker Triggered: Too many failures. Cooling down for 60s...")
                time.sleep(60)
                consecutive_fails = 0 # Reset

            market = self._get_market(symbol)
            if target_markets and market not in target_markets:
                continue
                
            # --- OPTIMIZATION: Skip if Daily Data Exists ---
            if self._is_daily_data_current(symbol, market):
                self.logger.info(f"Skipping Daily Fetch for {symbol}: Data for today already exists.")
                # We can still fetch minute data if needed, but usually 'fetch_all_stocks' is for sync
                # If minute data is needed, we proceed? 
                # User said "marketdata_full... same date only save one".
                # Let's skip DAILY fetch but maybe allow Minute?
                # But logic below mixes them.
                # Let's set a flag to skip daily part.
                skip_daily = True
            else:
                skip_daily = False
                
            period_data = {}

            if market == "US":
                symbol_daily = self.to_akshare_us_symbol(symbol, for_minute=False)
                symbol_min = self.to_akshare_us_symbol(symbol, for_minute=True)
                # æ—¥çº¿
                if not skip_daily:
                    daily_df = self.fetch_us_daily_data(symbol_daily)
                    if daily_df is not None and not daily_df.empty:
                        period_data['1d'] = daily_df
                        self.save_to_db(symbol, market, {'1d': daily_df}) # Save daily data
                # åˆ†é’Ÿçº¿
                df_1min = self.fetch_us_min_data(symbol_min)
                if df_1min is not None and not df_1min.empty:
                    period_data['1min'] = df_1min
                    self.save_to_db(symbol, market, {'1min': df_1min}) # Save minute data
            elif market == "CN":
                if not skip_daily:
                    daily_df = self.fetch_cn_daily_data(symbol)
                    if daily_df is not None and not daily_df.empty:
                        period_data['1d'] = daily_df
                        self.save_to_db(symbol, market, {'1d': daily_df}) # Save daily data
                else:
                    daily_df = None
                # Fund flow
                self.save_fund_flow(symbol) 
            elif market == "HK":
                if not skip_daily:
                    daily_df = self.fetch_hk_daily_data(symbol)
                    if daily_df is not None and not daily_df.empty:
                        period_data['1d'] = daily_df
                        self.save_to_db(symbol, market, {'1d': daily_df}) # Save daily data
                else: 
                    daily_df = None
            else:
                daily_df = None
                
            # CRITICAL FIX: Also fetch "Latest Snapshot" for Watchlist display (Real-time price)
            # Historical daily data often lags by 1 day or doesn't have intra-day 'change'.
            try:
                snapshot = self.fetch_latest_data(symbol, market, force_refresh=True)
                if snapshot:
                    # We inject this as a special updates to the DB directly, 
                    # ensuring the Watchlist has valid Price/Change.
                    # Since we are already creating period_data, we can't easily mix Dict snapshot with DataFrame history.
                    # Best to call a helper to save this snapshot.
                    from models import MarketDataDaily
                    from sqlmodel import select
                    from datetime import datetime
                    from database import get_session # Use get_session for consistency
                    
                    gen = get_session()
                    session = next(gen, None)
                    if not session:
                        self.logger.error("Could not get DB session for snapshot update")
                    else:
                        try:
                            stmt = select(MarketDataDaily).where(
                                MarketDataDaily.symbol == normalize_symbol_db(symbol, market),
                                MarketDataDaily.market == market
                            ).order_by(MarketDataDaily.date.desc())
                            existing = session.exec(stmt).first()
                            
                            # If no latest data, or snapshot is newer? 
                            # Just overwrite/update the latest 1d record to start with.
                            if not existing:
                                existing = MarketDataDaily(
                                    symbol=normalize_symbol_db(symbol, market), market=market, period='1d',
                                    date=snapshot['date'],
                                    open=snapshot['open'], high=snapshot['high'], low=snapshot['low'], close=snapshot['close'],
                                    volume=snapshot['volume'],
                                    pct_change=snapshot.get('pct_change'),
                                    change=snapshot.get('change'),
                                    updated_at=datetime.now()
                                )
                                session.add(existing)
                            else:
                                # Update fields
                                existing.close = snapshot['close']
                                existing.pct_change = snapshot.get('pct_change')
                                existing.change = snapshot.get('change')
                                existing.volume = snapshot['volume'] # Cumulative volume
                                existing.date = snapshot['date'] # Update Time to latest
                                existing.updated_at = datetime.now()
                                session.add(existing)
                            session.commit()
                            self.logger.info(f"Updated Snapshot for {symbol}")
                        except Exception as e:
                            session.rollback()
                            self.logger.error(f"Snapshot DB update failed: {e}")
                        finally:
                            session.close()

            except Exception as e:
                self.logger.error(f"Snapshot fetch failed in batch: {e}")


            # å„åˆ†é’Ÿçº¿ (US logic in original code only loops if periods passed, but US calc above did 1min explicitly)
            # Original code logic:
            # For each period in periods:
            #   fetch min data
            
            for period in periods:
                df = None
                if market == "US" and period == "1":
                    # Already fetched above potentially, but let's follow logic
                    # Original code fetched 1min above for US regardless of 'periods' arg? 
                    # Actually original code:
                    # if market == "US": ... fetch 1min ... period_data['1min'] = ...
                    # then loop periods...
                    # if market == "US" and period == "1": fetch_us_min_data(symbol)
                    # It seems redundant or specific.
                    # Let's trust original logic but ensure we don't double fetch if 1min is already there.
                    if '1min' in period_data:
                        df = period_data['1min']
                    else:
                        symbol_min = self.to_akshare_us_symbol(symbol, for_minute=True)
                        df = self.fetch_us_min_data(symbol_min)
                        if df is not None and not df.empty:
                            df = self._fix_open_price(df)
                            period_data[f'{period}min'] = df
                            self.save_to_db(symbol, market, {f'{period}min': df}) # Save minute data

                elif market == "HK":
                    df = self.fetch_hk_min_data(symbol, period=period)
                    if df is not None and not df.empty:
                        df = self._fix_open_price(df)
                        period_data[f'{period}min'] = df
                        self.save_to_db(symbol, market, {f'{period}min': df}) # Save minute data
                elif market == "CN":
                    df = self.fetch_cn_min_data(symbol, period=period)
                    if df is not None and not df.empty:
                        df = self._fix_open_price(df)
                        period_data[f'{period}min'] = df
                        self.save_to_db(symbol, market, {f'{period}min': df}) # Save minute data
                
            # Saving to Excel is now separate from DB save, and uses period_data
            if period_data:
                self._save_stock_to_excel(symbol, market, period_data)

    def fetch_single_stock(self, symbol: str, periods=None):
        if periods is None:
            periods = ['1d', '1', '5']
            
        market = self._get_market(symbol)
        self.logger.info(f"Fetching single stock {symbol} ({market})...")
        
        period_data = {}

        # 1. Daily Data
        daily_df = None
        if market == "US":
            symbol_daily = self.to_akshare_us_symbol(symbol, for_minute=False)
            daily_df = self.fetch_us_daily_data(symbol_daily)
        elif market == "CN":
            daily_df = self.fetch_cn_daily_data(symbol)
        elif market == "HK":
            daily_df = self.fetch_hk_daily_data(symbol)
            
        if daily_df is not None and not daily_df.empty:
            period_data['1d'] = daily_df
            self.save_to_db(symbol, market, {'1d': daily_df}) # Save daily data

        # 2. Minute Data
        # Only fetch '1' and '5' for efficiency if not specified
        target_periods = [p for p in periods if p != '1d']
        
        for period in target_periods:
            df = None
            if market == "US":
                # For US minute, we use the specific symbol format if needed, or just symbol?
                # fetch_us_min_data uses 'symbol' argument and calls stock_us_hist_min_em(symbol=symbol)
                # We need to make sure we pass what it expects.
                # fetch_all_stocks passed 'symbol_min' for 1min? 
                # Let's check fetch_all_stocks again. 
                # It did: symbol_min = self.to_akshare_us_symbol(symbol, for_minute=True)
                # then self.fetch_us_min_data(symbol_min)
                symbol_min = self.to_akshare_us_symbol(symbol, for_minute=True)
                df = self.fetch_us_min_data(symbol_min)
            elif market == "HK":
                df = self.fetch_hk_min_data(symbol, period=period)
            elif market == "CN":
                df = self.fetch_cn_min_data(symbol, period=period)
            
            if df is not None and not df.empty:
                df = self._fix_open_price(df)
                period_data[f'{period}min'] = df
                self.save_to_db(symbol, market, {f'{period}min': df}) # Save minute data

        # 3. Save
        if period_data:
            # We skip Excel for single stock fetch to save time? Or keep it?
            # Creating excel for every single add might be slow. Let's start with DB only for speed.
            # self._save_stock_to_excel(symbol, market, period_data) 
            
            # Log counts
            counts = {k: len(v) for k, v in period_data.items()}
            self.logger.info(f"Single stock fetch success for {symbol}: {counts} records.")
            return True
        else:
            self.logger.warning(f"Single stock fetch returned NO data for {symbol}")
        return False

    def _save_stock_to_excel(self, symbol, market, period_data):
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        market_dir = os.path.join(self.output_dir, market)
        os.makedirs(market_dir, exist_ok=True)
        filename = f"{symbol}_{market}_minute_data_{timestamp}_V4.xlsx"
        filepath = os.path.join(market_dir, filename)
        sheet_order = ['1d', '30min', '15min', '5min', '1min']
        ordered_keys = [k for k in sheet_order if k in period_data] + [k for k in period_data if k not in sheet_order]
        try:
            with pd.ExcelWriter(filepath) as writer:
                for period in ordered_keys:
                    df = period_data[period]
                    df.to_excel(writer, sheet_name=period, index=False)
            self.logger.info(f"Data for {symbol} saved to {filepath}")
        except Exception as e:
            self.logger.error(f"Failed to save excel for {symbol}: {e}")

    def _fix_open_price(self, df):
        df = df.copy()
        open_col = "å¼€ç›˜"

        close_col = "æ”¶ç›˜"
        if open_col in df.columns and close_col in df.columns:
            for i in range(1, len(df)):
                try:
                    if float(df.iloc[i][open_col]) == 0:
                        col_idx = df.columns.get_loc(open_col)
                        df.iloc[i, col_idx] = df.iloc[i-1][close_col]
                except Exception:
                    continue
        return df


    def to_akshare_us_symbol(self, s: str, for_minute: bool = False) -> str:
        """
        Convert potentially messy symbol to AkShare US format.
        Input: 'MSFT', '105.MSFT', 'MSFT.OQ'
        Output: '105.msft' (minute) or '105.MSFT' (daily)
        """
        s = s.upper() # Ensure upper first for comparisons
        # Clean suffix
        s_clean = s
        if s.endswith(".OQ") or s.endswith(".N") or s.endswith(".K"):
            s_clean = s.split('.')[0]
        
        s = s_clean
        prefix = "105." 
        
        # Already has prefix?
        if s.startswith("105.") or s.startswith("106."):
            if for_minute:
                return s.lower()
            return s.split(".")[1].upper()

        if s == "TSM": return "106.tsm" if for_minute else "TSM"
        
        if for_minute:
            return f"{prefix}{s.lower()}"
        else:
            return s

    def fetch_yahoo_indicators(self, symbol: str) -> dict:
        """
        Fetch supplementary indicators (PE, Dividend, etc.) and real-time quote from Yahoo Finance.
        Useful when AkShare lacks this specific metadata (like TTM Dividend Yield).
        """
        import yfinance as yf
        try:
            # Convert symbol to Yahoo format
            yf_symbol = symbol
            if symbol.endswith('.sh'):
                yf_symbol = symbol.replace('.sh', '.SS')
            elif symbol.endswith('.sz'):
                yf_symbol = symbol.replace('.sz', '.SZ')
            elif symbol.endswith('.hk'):
                try:
                    code = symbol.replace('.hk', '')
                    yf_symbol = f"{int(code):04d}.HK"
                except:
                    yf_symbol = symbol
            elif symbol.startswith('105.') or symbol.startswith('106.'):
                # US Stock
                yf_symbol = symbol.split('.')[-1].upper()
            elif symbol.startswith('^'):
                yf_symbol = symbol
            else:
                 # Clean US suffix like .OQ, .N for Yahoo
                 if symbol.endswith(".OQ") or symbol.endswith(".N"):
                     yf_symbol = symbol.split('.')[0]
            
            self.logger.info(f"Fetching Yahoo indicators for {yf_symbol}...")
            # é™æµ
            self.rate_limiter.wait_if_needed(symbol, 'yfinance')
            ticker = yf.Ticker(yf_symbol)
            info = ticker.info
            
            if not info:
                return {}
            
            return {
                "pe": info.get("trailingPE") or info.get("forwardPE"),
                "dividend_yield": info.get("dividendYield"),
                "market_cap": info.get("marketCap"),
                "prev_close": info.get("previousClose"),
                "currentPrice": info.get("currentPrice"),
                "price": info.get("currentPrice") or info.get("regularMarketPrice"), # Alias for compatibility
                "open": info.get("open") or info.get("regularMarketOpen"),
                "high": info.get("dayHigh") or info.get("regularMarketDayHigh"),
                "low": info.get("dayLow") or info.get("regularMarketDayLow"),
                "volume": info.get("volume") or info.get("regularMarketVolume"),
                "longName": info.get("longName"),
                "eps": info.get("trailingEps") or info.get("forwardEps")
            }
        except Exception as e:
            self.logger.error(f"Yahoo Fetch Failed: {e}")
            return {}

    # --- Refactor: New Async-Compatible Methods ---

    def get_db_snapshot(self, symbol: str, market: str):
        """
        Rule 3 & 4: Pure DB Read + Freshness Check.
        Returns: (data_dict, needs_update_bool)
        
        âœ… ä¿®å¤ï¼šä»MarketSnapshotè¡¨è¯»å–ï¼ˆè€ŒéMarketDataDailyï¼‰
        """
        from market_schedule import MarketSchedule
        from datetime import datetime, timedelta
        from sqlmodel import Session, select
        from models import MarketSnapshot
        
        with Session(self.engine) as session:
            # âœ… ä»MarketSnapshotè¡¨è¯»å–
            latest_snapshot = session.exec(
                select(MarketSnapshot)
                .where(MarketSnapshot.symbol == normalize_symbol_db(symbol, market))
                .where(MarketSnapshot.market == market)
            ).first()
            
            if not latest_snapshot:
                return None, True 
            
            # Check Stale
            last_time = latest_snapshot.updated_at if latest_snapshot.updated_at else datetime.now() - timedelta(days=1)
            is_stale = MarketSchedule.is_stale(last_time, market, ttl_seconds=60)
            
            # Convert to dict
            data = {
                "symbol": latest_snapshot.symbol,
                "price": latest_snapshot.price,
                "change": latest_snapshot.change,
                "pct_change": latest_snapshot.pct_change,
                "volume": latest_snapshot.volume,
                "market": market,
                "date": latest_snapshot.date,
                "pe": latest_snapshot.pe,
                "dividend_yield": latest_snapshot.dividend_yield,
                "open": latest_snapshot.open,
                "high": latest_snapshot.high,
                "low": latest_snapshot.low,
                "prev_close": latest_snapshot.prev_close
            }
            return data, is_stale

    def sync_market_data(self, symbol: str, market: str):
        """
        Rule 4: API Fetch -> Write DB.
        Should be called by Background Task.
        """
        self.fetch_latest_data(symbol, market, force_refresh=True)

    async def close(self):
        """Cleanup resources"""
        if self.session and not self.session.closed:
            await self.session.close()

    def repair_daily_data(self, symbol: str, market: str) -> dict:
        """
        Verify and repair missing change/pct_change in MarketDataDaily.
        Returns dict with status and fixed_count.
        """
        try:
            from database import engine
            from models import MarketDataDaily
            from sqlmodel import select, col, Session
            
            with Session(engine) as session:

                db_symbol = normalize_symbol_db(symbol, market)
                fixed_count = 0
                
                # --- 1. MarketDataDaily Repair ---
                # Use ILIKE for case-insensitive match to find bad symbols
                records = session.exec(
                    select(MarketDataDaily)
                    .where(MarketDataDaily.symbol.ilike(db_symbol), MarketDataDaily.market == market)
                    .order_by(MarketDataDaily.date.asc())
                ).all()
                
                if records:
                    for i in range(len(records)):
                        curr = records[i]
                        is_modified = False
                        
                        # A. Fix Symbol Case
                        if curr.symbol != db_symbol:
                            curr.symbol = db_symbol
                            is_modified = True
                            fixed_count += 1
                            
                        # A2. Fix Timestamp for Market Close Accuracy
                        # CN -> 15:00, HK -> 16:00, US -> 16:00 (Check timezone)
                        try:
                             # Handle Date String
                             d_str = str(curr.date)
                             new_d_str = d_str
                             
                             if market == 'CN' and d_str.endswith('00:00:00'):
                                 new_d_str = d_str.replace('00:00:00', '15:00:00')
                             elif market == 'HK' and d_str.endswith('00:00:00'):
                                 new_d_str = d_str.replace('00:00:00', '16:00:00')
                             elif market == 'US':
                                 # US Complex logic: 
                                 # 1. If 00:00:00 -> Set to 16:00:00 (Same Day)
                                 if d_str.endswith('00:00:00'):
                                     new_d_str = d_str.replace('00:00:00', '16:00:00')
                                 # 2. If 04:00/05:00/06:00 -> Likely BJ time for next day -> Shift back to prev day 16:00
                                 elif ' 04:' in d_str or ' 05:' in d_str or ' 06:' in d_str:
                                     # Parse, subtract day, set 16:00
                                     dt = pd.to_datetime(d_str) - pd.Timedelta(days=1)
                                     new_d_str = dt.strftime('%Y-%m-%d 16:00:00')
                             
                             if new_d_str != d_str:
                                 curr.date = new_d_str
                                 is_modified = True
                                 fixed_count += 1
                        except Exception as date_e:
                            self.logger.error(f"Date repair failed for {curr.date}: {date_e}")

                        # B. Fix Missing Change/PctChange
                        needs_repair = (curr.change is None or curr.change == 0) and \
                                       (curr.pct_change is None or curr.pct_change == 0) and \
                                       (curr.close is not None and curr.close > 0)
                        
                        if needs_repair:
                            prev_close = None
                            if i > 0:
                                 if records[i-1].close and records[i-1].close > 0:
                                     prev_close = records[i-1].close
                            
                            if prev_close:
                                change_val = curr.close - prev_close
                                pct_val = (change_val / prev_close) * 100
                                
                                curr.change = round(change_val, 4)
                                curr.pct_change = round(pct_val, 4)
                                curr.updated_at = datetime.now()
                                is_modified = True
                                fixed_count += 1
                        
                        if is_modified:
                            session.add(curr)

                # --- 2. MarketDataMinute Repair (Symbol Only) ---
                # Minute data heavily relies on prev close for pct_change which is harder to track in bulk efficiently here.
                # We focus on fixing the Symbol case to ensure visibility.
                min_records = session.exec(
                    select(MarketDataMinute)
                    .where(MarketDataMinute.symbol.ilike(db_symbol), MarketDataMinute.market == market)
                ).all()
                
                min_fixed = 0
                if min_records:
                    for mm in min_records:
                        if mm.symbol != db_symbol:
                            mm.symbol = db_symbol
                            session.add(mm)
                            min_fixed += 1
                
                if fixed_count > 0 or min_fixed > 0:
                    session.commit()
                    self.logger.info(f"Repaired {fixed_count} daily + {min_fixed} minute records for {db_symbol}")
                    return {"status": "success", "fixed_daily": fixed_count, "fixed_minute": min_fixed, "symbol": db_symbol}
                else:
                    return {"status": "success", "fixed_count": 0, "symbol": db_symbol, "message": "No repairs needed"}
                
        except Exception as e:
            self.logger.error(f"Error repairing data for {symbol}: {e}")
            return {"status": "error", "message": str(e)}

    def repair_minute_data(self, symbol: str, market: str, date_filter: str = None) -> dict:
        """
        Repair missing change/pct_change in MarketDataMinute.
        Calculates change relative to PREVIOUS DAY'S CLOSE (not previous minute).
        
        Args:
            symbol: Stock symbol
            market: Market type (CN/HK/US)
            date_filter: Optional date filter (e.g., '2025-12-15%') to repair specific day
        
        Returns:
            dict with status and fixed_count
        """
        try:
            from database import engine
            from models import MarketDataDaily
            from sqlmodel import select, Session
            
            with Session(engine) as session:

                db_symbol = normalize_symbol_db(symbol, market)
                fixed_count = 0
                
                # Query minute records
                stmt = select(MarketDataMinute).where(
                    MarketDataMinute.symbol == db_symbol,
                    MarketDataMinute.market == market
                )
                
                # Apply date filter if provided
                if date_filter:
                    stmt = stmt.where(MarketDataMinute.date.like(date_filter))
                
                stmt = stmt.order_by(MarketDataMinute.date.asc())
                records = session.exec(stmt).all()
                
                if not records:
                    return {"status": "success", "message": "No records found", "fixed_count": 0}
                
                self.logger.info(f"Repairing {len(records)} minute records for {db_symbol}")
                
                # Group records by trading day
                from collections import defaultdict
                import pandas as pd
                
                records_by_day = defaultdict(list)
                for record in records:
                    day = str(record.date).split(' ')[0]  # Extract date part
                    records_by_day[day].append(record)
                
                # Process each trading day
                for day, day_records in records_by_day.items():
                    # Get previous trading day's close
                    stmt_daily = select(MarketDataDaily).where(
                        MarketDataDaily.symbol == db_symbol,
                        MarketDataDaily.market == market,
                        MarketDataDaily.date < day
                    ).order_by(MarketDataDaily.date.desc()).limit(1)
                    
                    prev_day_record = session.exec(stmt_daily).first()
                    
                    if not prev_day_record or not prev_day_record.close:
                        self.logger.warning(f"No previous day close found for {db_symbol} on {day}, skipping")
                        continue
                    
                    prev_day_close = prev_day_record.close
                    self.logger.info(f"Using prev_day_close={prev_day_close} for {db_symbol} on {day}")
                    
                    # Calculate change for all minute records of this day relative to prev_day_close
                    for record in day_records:
                        # Check if repair is needed
                        needs_repair = (record.change is None or record.pct_change is None) and \
                                       (record.close is not None and record.close > 0)
                        
                        if needs_repair and prev_day_close > 0:
                            change_val = record.close - prev_day_close
                            pct_val = (change_val / prev_day_close) * 100
                            
                            record.change = round(change_val, 4)
                            record.pct_change = round(pct_val, 4)
                            record.updated_at = datetime.now()
                            
                            session.add(record)
                            fixed_count += 1
                
                if fixed_count > 0:
                    session.commit()
                    self.logger.info(f"Repaired {fixed_count} minute records for {db_symbol}")
                
                return {
                    "status": "success",
                    "fixed_count": fixed_count,
                    "total_records": len(records)
                }
            
        except Exception as e:
            self.logger.error(f"repair_minute_data failed for {symbol}: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return {"status": "error", "message": str(e)}


    def save_snapshot(self, symbol: str, market: str, data: dict, source: str = 'mixed') -> bool:
        """
        âš ï¸ DEPRECATED: This function bypasses ETL and should not be used.
        Use the unified ETL flow instead: save_to_db() â†’ RawMarketData â†’ ETL â†’ MarketSnapshot
        
        ä¿å­˜å¸‚åœºå¿«ç…§åˆ° MarketSnapshot è¡¨ï¼ˆUPSERTé€»è¾‘é˜²æ­¢é‡å¤ï¼‰
        
        ğŸ”¥ ETLèŒè´£ï¼šè®¡ç®—è¡¥å…¨ç¼ºå¤±çš„ change å’Œ pct_change
        
        Args:
            symbol: è‚¡ç¥¨ä»£å·
            market: å¸‚åœºï¼ˆCN, HK, USï¼‰
            data: æ•°æ®å­—å…¸ï¼Œå¿…é¡»åŒ…å« price, change, pct_changeç­‰
            source: æ•°æ®æ¥æº ('akshare', 'yfinance', 'tencent', 'mixed')
        
        Returns:
            bool: ä¿å­˜æˆåŠŸè¿”å›True
        """
        import warnings
        warnings.warn(
            "save_snapshot() is deprecated and bypasses ETL. Use save_to_db() instead.",
            DeprecationWarning,
            stacklevel=2
        )
        try:
            from database import engine
            from sqlmodel import Session, select
            from models import MarketSnapshot, MarketDataDaily
            from datetime import datetime
            
            # æ•°æ®éªŒè¯
            current_price = data.get('price') or data.get('close')
            if not current_price or current_price <= 0:
                self.logger.warning(f"Invalid price for {symbol}, skip saving")
                return False
            
            current_price = float(current_price)
            
            # æ ‡å‡†åŒ–symbol
            db_symbol = normalize_symbol_db(symbol, market)
            
            # === ETLè®¡ç®—è¡¥å…¨ï¼šå¼ºåˆ¶ä»å‰ä¸€æ—¥æ”¶ç›˜ä»·è®¡ç®— ===
            change = data.get('change')
            pct_change = data.get('pct_change')
            prev_close = None
            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦è®¡ç®—
            needs_calculation = (change is None or change == 0) and (pct_change is None or pct_change == 0)
            
            if needs_calculation:
                self.logger.info(f"ğŸ”§ ETL: Computing change for {symbol} from previous day's close")
                
                # ğŸ”¥ åªä»MarketDataDailyè¡¨æŸ¥è¯¢å‰ä¸€æ—¥æ”¶ç›˜ä»·ï¼ˆç”¨æˆ·è¦æ±‚ï¼‰
                with Session(engine) as temp_session:
                    prev_daily = temp_session.exec(
                        select(MarketDataDaily).where(
                            MarketDataDaily.symbol == db_symbol,
                            MarketDataDaily.market == market
                        ).order_by(MarketDataDaily.date.desc()).limit(1)
                    ).first()
                    
                    if prev_daily and prev_daily.close > 0:
                        prev_close = prev_daily.close
                        change = current_price - prev_close
                        pct_change = (change / prev_close) * 100
                        self.logger.info(f"âœ… Calculated from previous daily close: {change:.2f} ({pct_change:.2f}%)")
                    else:
                        # æ— æ³•è®¡ç®—ï¼Œä¿æŒä¸º0
                        self.logger.warning(f"âš ï¸ Cannot calculate change for {symbol}: no previous daily close found")
                        change = 0
                        pct_change = 0
            
            # ç¡®ä¿changeå’Œpct_changeæœ‰å€¼ï¼ˆå³ä½¿æ˜¯0ï¼‰
            change = float(change) if change is not None else 0.0
            pct_change = float(pct_change) if pct_change is not None else 0.0
            
            with Session(engine) as session:
                # UPSERTé€»è¾‘ï¼šæŸ¥è¯¢æ˜¯å¦å­˜åœ¨
                existing = session.exec(
                    select(MarketSnapshot).where(
                        MarketSnapshot.symbol == db_symbol,
                        MarketSnapshot.market == market
                    )
                ).first()
                
                if existing:
                    # UPDATE - æ›´æ–°ç°æœ‰è®°å½•
                    existing.price = current_price
                    existing.open = float(data.get('open', 0))
                    existing.high = float(data.get('high', 0))
                    existing.low = float(data.get('low', 0))
                    existing.prev_close = float(prev_close) if prev_close else None
                    existing.change = change
                    existing.pct_change = pct_change
                    existing.volume = int(data.get('volume', 0))
                    existing.turnover = float(data.get('turnover')) if data.get('turnover') else None
                    existing.pe = float(data.get('pe')) if data.get('pe') else None
                    existing.pb = float(data.get('pb')) if data.get('pb') else None
                    existing.dividend_yield = float(data.get('dividend_yield')) if data.get('dividend_yield') else None
                    existing.market_cap = float(data.get('market_cap')) if data.get('market_cap') else None
                    existing.date = str(data.get('date', datetime.now().strftime('%Y-%m-%d %H:%M:%S')))
                    existing.data_source = source
                    existing.updated_at = datetime.now()
                    
                    session.add(existing)
                    self.logger.info(f"âœ… Updated MarketSnapshot for {db_symbol} (change={change:.2f}, pct={pct_change:.2f}%)")
                else:
                    # INSERT - åˆ›å»ºæ–°è®°å½•
                    new_snapshot = MarketSnapshot(
                        symbol=db_symbol,
                        market=market,
                        price=current_price,
                        open=float(data.get('open', 0)),
                        high=float(data.get('high', 0)),
                        low=float(data.get('low', 0)),
                        prev_close=float(prev_close) if prev_close else None,
                        change=change,
                        pct_change=pct_change,
                        volume=int(data.get('volume', 0)),
                        turnover=float(data.get('turnover')) if data.get('turnover') else None,
                        pe=float(data.get('pe')) if data.get('pe') else None,
                        pb=float(data.get('pb')) if data.get('pb') else None,
                        dividend_yield=float(data.get('dividend_yield')) if data.get('dividend_yield') else None,
                        market_cap=float(data.get('market_cap')) if data.get('market_cap') else None,
                        date=str(data.get('date', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))),
                        data_source=source,
                        fetch_time=datetime.now(),
                        updated_at=datetime.now()
                    )
                    
                    session.add(new_snapshot)
                    self.logger.info(f"âœ… Inserted new MarketSnapshot for {db_symbol} (change={change:.2f}, pct={pct_change:.2f}%)")
                
                session.commit()
                return True
                
        except Exception as e:
            self.logger.error(f"Failed to save snapshot for {symbol}: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return False




    def backfill_missing_data(self, symbol: str, market: str, days: int = None) -> dict:
        """
        æ™ºèƒ½å›å¡«ç¼ºå¤±çš„å†å²æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            market: å¸‚åœº ('CN', 'HK', 'US')
            days: å›å¡«å¤©æ•°ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹ç¼ºå¤±èŒƒå›´
        """
        try:
            # æ™ºèƒ½æ£€æµ‹ç¼ºå¤±èŒƒå›´
            if days is None:
                from database import engine
                from sqlmodel import Session, select
                from models import MarketDataDaily
                from datetime import datetime, timedelta
                
                with Session(engine) as session:
                    # æŸ¥è¯¢æœ€æ–°æ•°æ®æ—¥æœŸ
                    latest = session.exec(
                        select(MarketDataDaily)
                        .where(MarketDataDaily.symbol == symbol)
                        .where(MarketDataDaily.market == market)
                        .order_by(MarketDataDaily.date.desc())
                        .limit(1)
                    ).first()
                    
                    if latest:
                        # è®¡ç®—ç¼ºå¤±å¤©æ•°
                        from datetime import datetime as dt
                        latest_date = latest.date
                        # ç¡®ä¿latest_dateæ˜¯datetimeå¯¹è±¡
                        if isinstance(latest_date, str):
                            latest_date = dt.fromisoformat(latest_date.replace(' ', 'T'))
                        today = datetime.now()
                        gap_days = (today - latest_date).days
                        
                        # è‡ªåŠ¨ç¡®å®šå›å¡«å¤©æ•°ï¼ˆæœ€å¤š90å¤©ï¼‰
                        days = min(max(gap_days + 5, 30), 90)
                        self.logger.info(f"  æ£€æµ‹åˆ°ç¼ºå¤±{gap_days}å¤©ï¼Œå°†å›å¡«{days}å¤©")
                    else:
                        # å…¨æ–°è‚¡ç¥¨ï¼Œå…¨é‡ä¸‹è½½æ‰€æœ‰å†å²æ•°æ®
                        days = None  # Noneè¡¨ç¤ºä¸é™åˆ¶ï¼Œä¸‹è½½å…¨éƒ¨
                        self.logger.info(f"  æ–°è‚¡ç¥¨ï¼Œå…¨é‡ä¸‹è½½æ‰€æœ‰å†å²æ•°æ®")
            
            self.logger.info(f"ğŸ”„ å¼€å§‹å›å¡« {symbol} ({market}) æœ€è¿‘{days}å¤©æ•°æ®")
            
            # 1. è·å–å®Œæ•´å†å²æ•°æ®
            df = None
            if market == 'CN':
                df = self.fetch_cn_daily_data(symbol)
            elif market == 'HK':
                df = self.fetch_hk_daily_data(symbol)
            elif market == 'US':
                df = self.fetch_us_daily_data(symbol)
            
            if df is None or df.empty:
                return {'success': False, 'message': 'æ— æ³•è·å–æ•°æ®'}
            
            # 2. ç­›é€‰æ•°æ®èŒƒå›´
            if days is None:
                # å…¨é‡ä¸‹è½½ï¼Œä¸é™åˆ¶
                self.logger.info(f"  å…¨é‡ä¸‹è½½: {len(df)} æ¡è®°å½•")
            else:
                # åªä¿ç•™æœ€è¿‘Nå¤©
                df = df.tail(days)
                self.logger.info(f"  ç­›é€‰æœ€è¿‘{days}å¤©: {len(df)} æ¡è®°å½•")
            
            records_fetched = len(df)
            
            # 3. ä¿å­˜åˆ°RawMarketData
            from models import RawMarketData
            from database import engine
            from sqlmodel import Session
            import json
            
            with Session(engine) as session:
                # è½¬æ¢æ‰€æœ‰æ—¥æœŸ/æ—¶é—´åˆ—ä¸ºå­—ç¬¦ä¸²ä»¥æ”¯æŒJSONåºåˆ—åŒ–
                df_json = df.copy()
                for col in df_json.columns:
                    if df_json[col].dtype == 'object' or 'timestamp' in col.lower() or 'date' in col.lower():
                        try:
                            df_json[col] = df_json[col].astype(str)
                        except:
                            pass
                
                payload = df_json.to_dict('records')
                raw = RawMarketData(
                    source='backfill',
                    symbol=symbol,
                    market=market,
                    period='1d',
                    payload=json.dumps(payload),
                    processed=0
                )
                session.add(raw)
                session.commit()
                session.refresh(raw)
                raw_id = raw.id
            
            # 4. è§¦å‘ETLå¤„ç†
            from etl_service import ETLService
            ETLService.process_raw_data(raw_id)
            
            self.logger.info(f"âœ… å›å¡«å®Œæˆ: {symbol}")
            return {
                'success': True,
                'symbol': symbol,
                'records_fetched': records_fetched,
                'message': f'æˆåŠŸå›å¡« {records_fetched} æ¡è®°å½•'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ å›å¡«å¤±è´¥ {symbol}: {e}")
            return {'success': False, 'message': f'å›å¡«å¤±è´¥: {str(e)}'}
    
    # ============================================================
    # ğŸš€ å¼‚æ­¥å¹¶å‘æ”¯æŒ (æ–¹æ¡ˆ1: å¹¶è¡Œæ•°æ®è·å–)
    # ============================================================
    
    async def fetch_latest_data_async(
        self,
        symbol: str,
        market: str,
        save_db: bool = True,
        force_refresh: bool = False
    ) -> Optional[dict]:
        """
        å¼‚æ­¥ç‰ˆæœ¬çš„fetch_latest_data
        
        åŒ…è£…åŒæ­¥å‡½æ•°è¿è¡Œåœ¨çº¿ç¨‹æ± ä¸­,æ”¯æŒå¹¶å‘è°ƒç”¨
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            market: å¸‚åœº (CN/HK/US)
            save_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
        
        Returns:
            æ•°æ®å­—å…¸,å¤±è´¥è¿”å›None
        
        æ€§èƒ½ä¼˜åŠ¿:
            - å¤šä¸ªè‚¡ç¥¨å¯ä»¥å¹¶å‘è·å–
            - ä¸é˜»å¡ä¸»çº¿ç¨‹
            - é…åˆasyncio.gatherå¯å®ç°çœŸæ­£çš„å¹¶è¡Œ
        """
        import asyncio
        from concurrent.futures import ThreadPoolExecutor
        
        # ç¡®ä¿çº¿ç¨‹æ± å­˜åœ¨
        if not hasattr(self, '_executor'):
            self._executor = ThreadPoolExecutor(max_workers=10)
        
        loop = asyncio.get_event_loop()
        
        # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥å‡½æ•°
        try:
            result = await loop.run_in_executor(
                self._executor,
                self.fetch_latest_data,
                symbol,
                market,
                save_db,
                force_refresh
            )
            return result
        except Exception as e:
            self.logger.error(f"Async fetch failed for {symbol}: {e}")
            return None

if __name__ == "__main__":
    pass

