#!/usr/bin/env python3
"""
PE å›å¡«è„šæœ¬ - æœ€ç»ˆä¼˜åŒ–ç‰ˆ
- é¢„åŠ è½½è´¢æŠ¥æ•°æ®
- ç¼“å­˜è‚¡æœ¬æ•°æ®
- æ­£ç¡®çš„ TTM å’Œæ±‡ç‡è®¡ç®—
"""
import sys
import time
from datetime import datetime
from sqlmodel import Session, select
import logging
from collections import defaultdict

# æ·»åŠ åç«¯è·¯å¾„
sys.path.append('backend')
from database import engine
from models import MarketDataDaily, Watchlist, FinancialFundamentals
from valuation_calculator import (
    get_ttm_net_income, 
    compute_ttm_eps_per_unit,
    get_shares_outstanding
)
from symbols_config import SYMBOLS_CONFIG, normalize_code

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("FinalBackfill")

# é…ç½®
BATCH_SIZE = 100
MAX_RETRIES = 3
RETRY_DELAY = 1

# å…¨å±€ç¼“å­˜
SHARES_CACHE = {}


def preload_all_financials(session: Session, symbols: list) -> dict:
    """æ‰¹é‡é¢„åŠ è½½æ‰€æœ‰è‚¡ç¥¨çš„è´¢æŠ¥æ•°æ®"""
    logger.info("ğŸ“¥ æ‰¹é‡é¢„åŠ è½½è´¢æŠ¥æ•°æ®...")
    
    financials_cache = defaultdict(list)
    
    all_financials = session.exec(
        select(FinancialFundamentals)
        .where(FinancialFundamentals.symbol.in_(symbols))
        .order_by(FinancialFundamentals.symbol, FinancialFundamentals.as_of_date.desc())
    ).all()
    
    for fin in all_financials:
        financials_cache[fin.symbol].append(fin)
    
    logger.info(f"âœ… é¢„åŠ è½½å®Œæˆ: {len(financials_cache)} ä¸ªè‚¡ç¥¨çš„è´¢æŠ¥æ•°æ®")
    return financials_cache


def get_shares_cached(symbol: str, market: str) -> float:
    """è·å–è‚¡æœ¬ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    if symbol not in SHARES_CACHE:
        try:
            shares = get_shares_outstanding(symbol, market)
            SHARES_CACHE[symbol] = shares
        except Exception as e:
            logger.warning(f"è·å– {symbol} è‚¡æœ¬å¤±è´¥: {e}")
            SHARES_CACHE[symbol] = None
    return SHARES_CACHE[symbol]


def calculate_pe_fast(
    symbol: str,
    market: str,
    close_price: float,
    as_of_date: str,
    financials_cache: list
) -> dict:
    """å¿«é€Ÿè®¡ç®— PEï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰"""
    try:
        # 1. è¿‡æ»¤æœ‰æ•ˆè´¢æŠ¥
        valid_fins = [f for f in financials_cache if f.as_of_date <= as_of_date]
        if not valid_fins:
            return {'eps': None, 'pe': None}
        
        # 2. è®¡ç®— TTM å‡€åˆ©æ¶¦
        ttm_income, fin_currency = get_ttm_net_income(valid_fins, as_of_date)
        if not ttm_income:
            return {'eps': None, 'pe': None}
        
        # 3. è·å–è‚¡æœ¬ï¼ˆç¼“å­˜ï¼‰
        shares = get_shares_cached(symbol, market)
        if not shares:
            return {'eps': None, 'pe': None}
        
        # 4. è·å–é…ç½®
        simple_code = normalize_code(symbol)
        config = SYMBOLS_CONFIG.get(simple_code, {})
        adr_ratio = config.get('adr_ratio', 1.0)
        
        market_currency_map = {'US': 'USD', 'HK': 'HKD', 'CN': 'CNY'}
        market_currency = market_currency_map.get(market, 'USD')
        
        # 5. è®¡ç®— EPS
        eps = compute_ttm_eps_per_unit(
            ttm_income,
            shares,
            fin_currency or market_currency,
            market_currency,
            adr_ratio
        )
        
        if not eps or eps == 0:
            return {'eps': None, 'pe': None}
        
        # 6. è®¡ç®— PE
        pe = close_price / eps
        return {'eps': eps, 'pe': pe}
        
    except Exception as e:
        logger.error(f"è®¡ç®— PE å¤±è´¥ ({symbol}): {e}")
        return {'eps': None, 'pe': None}


def commit_with_retry(session: Session, max_retries: int = MAX_RETRIES):
    """å¸¦é‡è¯•çš„æäº¤"""
    for attempt in range(max_retries):
        try:
            session.commit()
            return True
        except Exception as e:
            if 'database is locked' in str(e):
                if attempt < max_retries - 1:
                    logger.warning(f"  âš ï¸ æ•°æ®åº“é”å®šï¼Œ{RETRY_DELAY}ç§’åé‡è¯• ({attempt + 1}/{max_retries})")
                    time.sleep(RETRY_DELAY)
                    continue
                else:
                    logger.error(f"  âŒ æ•°æ®åº“é”å®šï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
                    session.rollback()
                    return False
            else:
                logger.error(f"  âŒ æäº¤å¤±è´¥: {e}")
                session.rollback()
                return False
    return False


def backfill_stock_pe(session: Session, symbol: str, market: str, financials_cache: dict):
    """å›å¡«å•ä¸ªè‚¡ç¥¨çš„ PE"""
    logger.info(f"æ­£åœ¨å›å¡« {symbol}...")
    
    records = session.exec(
        select(MarketDataDaily)
        .where(
            MarketDataDaily.symbol == symbol,
            MarketDataDaily.market == market
        )
        .order_by(MarketDataDaily.timestamp)
    ).all()
    
    if not records:
        logger.warning(f"  âš ï¸ æœªæ‰¾åˆ°å†å²æ•°æ®")
        return 0
    
    financials = financials_cache.get(symbol, [])
    if not financials:
        logger.warning(f"  âš ï¸ æœªæ‰¾åˆ°è´¢æŠ¥æ•°æ®")
        return 0
    
    logger.info(f"  å†å²æ•°æ®: {len(records)} æ¡, è´¢æŠ¥: {len(financials)} æ¡")
    
    updated_count = 0
    batch_count = 0
    
    for i, rec in enumerate(records, 1):
        try:
            date_str = str(rec.timestamp)[:10]
            
            pe_metrics = calculate_pe_fast(
                symbol, market, rec.close, date_str, financials
            )
            
            if pe_metrics['eps'] is not None or pe_metrics['pe'] is not None:
                rec.eps = pe_metrics['eps']
                rec.pe = pe_metrics['pe']
                rec.updated_at = datetime.now()
                session.add(rec)
                updated_count += 1
                batch_count += 1
            
            if batch_count >= BATCH_SIZE:
                if commit_with_retry(session):
                    logger.info(f"  ğŸ’¾ å·²æäº¤ {updated_count} æ¡ ({i}/{len(records)})")
                    batch_count = 0
                else:
                    logger.error(f"  âŒ æ‰¹æ¬¡æäº¤å¤±è´¥")
                    return updated_count
                
        except Exception as e:
            logger.error(f"  âŒ å¤„ç† {date_str} å¤±è´¥: {e}")
            continue
    
    if batch_count > 0:
        if commit_with_retry(session):
            logger.info(f"  ğŸ’¾ æœ€ç»ˆæäº¤ {batch_count} æ¡")
    
    logger.info(f"  âœ… å®Œæˆ: {updated_count}/{len(records)} æ¡")
    return updated_count


def main():
    """ä¸»å‡½æ•°"""
    logger.info("="*80)
    logger.info("ğŸš€ å¼€å§‹ PE å›å¡«ï¼ˆæœ€ç»ˆä¼˜åŒ–ç‰ˆï¼‰")
    logger.info("="*80)
    
    start_time = time.time()
    
    with Session(engine) as session:
        watchlist = session.exec(select(Watchlist)).all()
        stocks = [w for w in watchlist if 'STOCK' in w.symbol]
        
        logger.info(f"\næ‰¾åˆ° {len(stocks)} åªè‚¡ç¥¨")
        logger.info(f"æ‰¹æ¬¡å¤§å°: {BATCH_SIZE} æ¡/æ‰¹\n")
        
        # é¢„åŠ è½½è´¢æŠ¥
        symbols = [s.symbol for s in stocks]
        financials_cache = preload_all_financials(session, symbols)
        
        # é¢„åŠ è½½è‚¡æœ¬ï¼ˆé¿å…æ¯æ¡è®°å½•éƒ½è°ƒç”¨ APIï¼‰
        logger.info("ğŸ“¥ é¢„åŠ è½½è‚¡æœ¬æ•°æ®...")
        for i, stock in enumerate(stocks, 1):
            logger.info(f"  [{i}/{len(stocks)}] è·å– {stock.symbol} è‚¡æœ¬...")
            get_shares_cached(stock.symbol, stock.market)
        logger.info("âœ… è‚¡æœ¬é¢„åŠ è½½å®Œæˆ\n")
        
        # é€ä¸ªå›å¡«
        total_updated = 0
        for i, stock in enumerate(stocks, 1):
            logger.info(f"\n[{i}/{len(stocks)}] {stock.symbol}")
            
            try:
                count = backfill_stock_pe(session, stock.symbol, stock.market, financials_cache)
                total_updated += count
                
                elapsed = time.time() - start_time
                avg_time = elapsed / i
                remaining = avg_time * (len(stocks) - i)
                logger.info(f"  â±ï¸  å·²ç”¨æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ, é¢„è®¡å‰©ä½™: {remaining/60:.1f}åˆ†é’Ÿ")
                    
            except Exception as e:
                logger.error(f"  âŒ å›å¡«å¤±è´¥: {e}")
                continue
    
    elapsed = time.time() - start_time
    logger.info("\n" + "="*80)
    logger.info(f"âœ… å›å¡«å®Œæˆï¼å…±æ›´æ–° {total_updated} æ¡è®°å½•")
    logger.info(f"â±ï¸  æ€»ç”¨æ—¶: {elapsed/60:.1f} åˆ†é’Ÿ")
    logger.info("="*80)


if __name__ == "__main__":
    main()
